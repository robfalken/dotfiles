{"id":"458b3613-4b87-428f-9b2d-c738fa95484c","zed":"context","version":"0.4.0","text":"\n\n\nYou are a senior software engineering consultant with 15+ years of experience, specializing in:\n\nTechnical Expertise:\n- Cloud Infrastructure & DevOps\n  * AWS CDK, CloudFormation, and AWS best practices\n  * CI/CD pipelines and automation\n  * Infrastructure as Code (IaC)\n  * Container orchestration (Docker, Kubernetes)\n\nProgramming Languages & Frameworks:\n- Rust\n  * Systems programming and performance optimization\n  * Memory safety and concurrent programming\n  * Popular crates and ecosystem\n- Ruby\n  * Rails framework and web development\n  * Testing frameworks (RSpec, Minitest)\n  * Gem development and management\n- TypeScript\n  * Advanced type system features\n  * Node.js backend development\n  * Modern ES6+ features\n- React\n  * Modern React patterns (Hooks, Context)\n  * State management (Redux, MobX)\n  * Performance optimization\n  * Component architecture\n\nArchitecture & Design:\n- Microservices architecture\n- Domain-Driven Design\n- RESTful API design\n- Event-driven architecture\n- System scalability and reliability\n- Security best practices\n\nYou excel at:\n- Code review and quality assessment\n- Architectural decision making\n- Performance optimization\n- Technical debt management\n- Best practices and design patterns\n- Clear technical communication\n\nPlease provide practical, production-ready advice with concrete examples when possible.\n```\n\nThis improved prompt:\n\n1. Specifies experience level\n2. Breaks down expertise into clear categories\n3. Provides specific sub-skills within each area\n4. Includes soft skills and consulting capabilities\n5. Sets expectations for the type of advice needed\n6. Gives more context for better-targeted responses\n\nYou can further customize this by:\n- Adding specific versions/tools you work with\n- Including industry-specific knowledge\n- Specifying methodology preferences (Agile, etc.)\n- Adding any specific certification requirements\n- Including any company-specific constraints or preferences\n\nRemember to adjust the areas of expertise based on your specific needs for each conversation.\n```rs zed/crates/project/src/project.rs\npub mod buffer_store;\nmod color_extractor;\npub mod connection_manager;\npub mod debounced_delay;\npub mod git;\npub mod image_store;\npub mod lsp_command;\npub mod lsp_ext_command;\npub mod lsp_store;\npub mod prettier_store;\npub mod project_settings;\npub mod search;\nmod task_inventory;\npub mod task_store;\npub mod terminals;\npub mod toolchain_store;\npub mod worktree_store;\n\n#[cfg(test)]\nmod project_tests;\n\nmod direnv;\nmod environment;\nuse buffer_diff::BufferDiff;\npub use environment::EnvironmentErrorMessage;\nuse git::Repository;\npub mod search_history;\nmod yarn;\n\nuse crate::git::GitState;\nuse anyhow::{anyhow, Context as _, Result};\nuse buffer_store::{BufferStore, BufferStoreEvent};\nuse client::{\n    proto, Client, Collaborator, PendingEntitySubscription, ProjectId, TypedEnvelope, UserStore,\n};\nuse clock::ReplicaId;\nuse collections::{BTreeSet, HashMap, HashSet};\nuse debounced_delay::DebouncedDelay;\npub use environment::ProjectEnvironment;\nuse futures::{\n    channel::mpsc::{self, UnboundedReceiver},\n    future::try_join_all,\n    StreamExt,\n};\npub use image_store::{ImageItem, ImageStore};\nuse image_store::{ImageItemEvent, ImageStoreEvent};\n\nuse ::git::{\n    blame::Blame,\n    repository::{Branch, GitRepository, RepoPath},\n    status::FileStatus,\n};\nuse gpui::{\n    AnyEntity, App, AppContext as _, AsyncApp, BorrowAppContext, Context, Entity, EventEmitter,\n    Hsla, SharedString, Task, WeakEntity, Window,\n};\nuse itertools::Itertools;\nuse language::{\n    language_settings::InlayHintKind, proto::split_operations, Buffer, BufferEvent,\n    CachedLspAdapter, Capability, CodeLabel, CompletionDocumentation, File as _, Language,\n    LanguageName, LanguageRegistry, PointUtf16, ToOffset, ToPointUtf16, Toolchain, ToolchainList,\n    Transaction, Unclipped,\n};\nuse lsp::{\n    CodeActionKind, CompletionContext, CompletionItemKind, DocumentHighlightKind, LanguageServer,\n    LanguageServerId, LanguageServerName, MessageActionItem,\n};\nuse lsp_command::*;\nuse lsp_store::LspFormatTarget;\nuse node_runtime::NodeRuntime;\nuse parking_lot::Mutex;\npub use prettier_store::PrettierStore;\nuse project_settings::{ProjectSettings, SettingsObserver, SettingsObserverEvent};\nuse remote::{SshConnectionOptions, SshRemoteClient};\nuse rpc::{\n    proto::{FromProto, LanguageServerPromptResponse, ToProto, SSH_PROJECT_ID},\n    AnyProtoClient, ErrorCode,\n};\nuse search::{SearchInputKind, SearchQuery, SearchResult};\nuse search_history::SearchHistory;\nuse settings::{InvalidSettingsError, Settings, SettingsLocation, SettingsStore};\nuse smol::channel::Receiver;\nuse snippet::Snippet;\nuse snippet_provider::SnippetProvider;\nuse std::{\n    borrow::Cow,\n    ops::Range,\n    path::{Component, Path, PathBuf},\n    pin::pin,\n    str,\n    sync::Arc,\n    time::Duration,\n};\nuse task_store::TaskStore;\nuse terminals::Terminals;\nuse text::{Anchor, BufferId};\nuse toolchain_store::EmptyToolchainStore;\nuse util::{paths::compare_paths, ResultExt as _};\nuse worktree::{CreatedEntry, Snapshot, Traversal};\nuse worktree_store::{WorktreeStore, WorktreeStoreEvent};\n\npub use fs::*;\npub use language::Location;\n#[cfg(any(test, feature = \"test-support\"))]\npub use prettier::FORMAT_SUFFIX as TEST_PRETTIER_FORMAT_SUFFIX;\npub use task_inventory::{\n    BasicContextProvider, ContextProviderWithTasks, Inventory, TaskSourceKind,\n};\npub use worktree::{\n    Entry, EntryKind, File, LocalWorktree, PathChange, ProjectEntryId, UpdatedEntriesSet,\n    UpdatedGitRepositoriesSet, Worktree, WorktreeId, WorktreeSettings, FS_WATCH_LATENCY,\n};\n\npub use buffer_store::ProjectTransaction;\npub use lsp_store::{\n    DiagnosticSummary, LanguageServerLogType, LanguageServerProgress, LanguageServerPromptRequest,\n    LanguageServerStatus, LanguageServerToQuery, LspStore, LspStoreEvent,\n    SERVER_PROGRESS_THROTTLE_TIMEOUT,\n};\npub use toolchain_store::ToolchainStore;\nconst MAX_PROJECT_SEARCH_HISTORY_SIZE: usize = 500;\nconst MAX_SEARCH_RESULT_FILES: usize = 5_000;\nconst MAX_SEARCH_RESULT_RANGES: usize = 10_000;\n\npub trait ProjectItem {\n    fn try_open(\n        project: &Entity<Project>,\n        path: &ProjectPath,\n        cx: &mut App,\n    ) -> Option<Task<Result<Entity<Self>>>>\n    where\n        Self: Sized;\n    fn entry_id(&self, cx: &App) -> Option<ProjectEntryId>;\n    fn project_path(&self, cx: &App) -> Option<ProjectPath>;\n    fn is_dirty(&self) -> bool;\n}\n\n#[derive(Clone)]\npub enum OpenedBufferEvent {\n    Disconnected,\n    Ok(BufferId),\n    Err(BufferId, Arc<anyhow::Error>),\n}\n\n/// Semantics-aware entity that is relevant to one or more [`Worktree`] with the files.\n/// `Project` is responsible for tasks, LSP and collab queries, synchronizing worktree states accordingly.\n/// Maps [`Worktree`] entries with its own logic using [`ProjectEntryId`] and [`ProjectPath`] structs.\n///\n/// Can be either local (for the project opened on the same host) or remote.(for collab projects, browsed by multiple remote users).\npub struct Project {\n    active_entry: Option<ProjectEntryId>,\n    buffer_ordered_messages_tx: mpsc::UnboundedSender<BufferOrderedMessage>,\n    languages: Arc<LanguageRegistry>,\n    client: Arc<client::Client>,\n    join_project_response_message_id: u32,\n    task_store: Entity<TaskStore>,\n    user_store: Entity<UserStore>,\n    fs: Arc<dyn Fs>,\n    ssh_client: Option<Entity<SshRemoteClient>>,\n    client_state: ProjectClientState,\n    git_state: Entity<GitState>,\n    collaborators: HashMap<proto::PeerId, Collaborator>,\n    client_subscriptions: Vec<client::Subscription>,\n    worktree_store: Entity<WorktreeStore>,\n    buffer_store: Entity<BufferStore>,\n    image_store: Entity<ImageStore>,\n    lsp_store: Entity<LspStore>,\n    _subscriptions: Vec<gpui::Subscription>,\n    buffers_needing_diff: HashSet<WeakEntity<Buffer>>,\n    git_diff_debouncer: DebouncedDelay<Self>,\n    remotely_created_models: Arc<Mutex<RemotelyCreatedModels>>,\n    terminals: Terminals,\n    node: Option<NodeRuntime>,\n    search_history: SearchHistory,\n    search_included_history: SearchHistory,\n    search_excluded_history: SearchHistory,\n    snippets: Entity<SnippetProvider>,\n    environment: Entity<ProjectEnvironment>,\n    settings_observer: Entity<SettingsObserver>,\n    toolchain_store: Option<Entity<ToolchainStore>>,\n}\n\n#[derive(Default)]\nstruct RemotelyCreatedModels {\n    worktrees: Vec<Entity<Worktree>>,\n    buffers: Vec<Entity<Buffer>>,\n    retain_count: usize,\n}\n\nstruct RemotelyCreatedModelGuard {\n    remote_models: std::sync::Weak<Mutex<RemotelyCreatedModels>>,\n}\n\nimpl Drop for RemotelyCreatedModelGuard {\n    fn drop(&mut self) {\n        if let Some(remote_models) = self.remote_models.upgrade() {\n            let mut remote_models = remote_models.lock();\n            assert!(\n                remote_models.retain_count > 0,\n                \"RemotelyCreatedModelGuard dropped too many times\"\n            );\n            remote_models.retain_count -= 1;\n            if remote_models.retain_count == 0 {\n                remote_models.buffers.clear();\n                remote_models.worktrees.clear();\n            }\n        }\n    }\n}\n/// Message ordered with respect to buffer operations\n#[derive(Debug)]\nenum BufferOrderedMessage {\n    Operation {\n        buffer_id: BufferId,\n        operation: proto::Operation,\n    },\n    LanguageServerUpdate {\n        language_server_id: LanguageServerId,\n        message: proto::update_language_server::Variant,\n    },\n    Resync,\n}\n\n#[derive(Debug)]\nenum ProjectClientState {\n    /// Single-player mode.\n    Local,\n    /// Multi-player mode but still a local project.\n    Shared { remote_id: u64 },\n    /// Multi-player mode but working on a remote project.\n    Remote {\n        sharing_has_stopped: bool,\n        capability: Capability,\n        remote_id: u64,\n        replica_id: ReplicaId,\n    },\n}\n\n#[derive(Clone, Debug, PartialEq)]\npub enum Event {\n    LanguageServerAdded(LanguageServerId, LanguageServerName, Option<WorktreeId>),\n    LanguageServerRemoved(LanguageServerId),\n    LanguageServerLog(LanguageServerId, LanguageServerLogType, String),\n    Toast {\n        notification_id: SharedString,\n        message: String,\n    },\n    HideToast {\n        notification_id: SharedString,\n    },\n    LanguageServerPrompt(LanguageServerPromptRequest),\n    LanguageNotFound(Entity<Buffer>),\n    ActiveEntryChanged(Option<ProjectEntryId>),\n    ActivateProjectPanel,\n    WorktreeAdded(WorktreeId),\n    WorktreeOrderChanged,\n    WorktreeRemoved(WorktreeId),\n    WorktreeUpdatedEntries(WorktreeId, UpdatedEntriesSet),\n    WorktreeUpdatedGitRepositories(WorktreeId),\n    DiskBasedDiagnosticsStarted {\n        language_server_id: LanguageServerId,\n    },\n    DiskBasedDiagnosticsFinished {\n        language_server_id: LanguageServerId,\n    },\n    DiagnosticsUpdated {\n        path: ProjectPath,\n        language_server_id: LanguageServerId,\n    },\n    RemoteIdChanged(Option<u64>),\n    DisconnectedFromHost,\n    DisconnectedFromSshRemote,\n    Closed,\n    DeletedEntry(WorktreeId, ProjectEntryId),\n    CollaboratorUpdated {\n        old_peer_id: proto::PeerId,\n        new_peer_id: proto::PeerId,\n    },\n    CollaboratorJoined(proto::PeerId),\n    CollaboratorLeft(proto::PeerId),\n    HostReshared,\n    Reshared,\n    Rejoined,\n    RefreshInlayHints,\n    RevealInProjectPanel(ProjectEntryId),\n    SnippetEdit(BufferId, Vec<(lsp::Range, Snippet)>),\n    ExpandedAllForEntry(WorktreeId, ProjectEntryId),\n}\n\n#[derive(Clone, Debug, Eq, PartialEq, Hash, PartialOrd, Ord)]\npub struct ProjectPath {\n    pub worktree_id: WorktreeId,\n    pub path: Arc<Path>,\n}\n\nimpl ProjectPath {\n    pub fn from_proto(p: proto::ProjectPath) -> Self {\n        Self {\n            worktree_id: WorktreeId::from_proto(p.worktree_id),\n            path: Arc::<Path>::from_proto(p.path),\n        }\n    }\n\n    pub fn to_proto(&self) -> proto::ProjectPath {\n        proto::ProjectPath {\n            worktree_id: self.worktree_id.to_proto(),\n            path: self.path.as_ref().to_proto(),\n        }\n    }\n\n    pub fn root_path(worktree_id: WorktreeId) -> Self {\n        Self {\n            worktree_id,\n            path: Path::new(\"\").into(),\n        }\n    }\n}\n\n#[derive(Debug, Default)]\npub enum PrepareRenameResponse {\n    Success(Range<Anchor>),\n    OnlyUnpreparedRenameSupported,\n    #[default]\n    InvalidPosition,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub struct InlayHint {\n    pub position: language::Anchor,\n    pub label: InlayHintLabel,\n    pub kind: Option<InlayHintKind>,\n    pub padding_left: bool,\n    pub padding_right: bool,\n    pub tooltip: Option<InlayHintTooltip>,\n    pub resolve_state: ResolveState,\n}\n\n/// The user's intent behind a given completion confirmation\n#[derive(PartialEq, Eq, Hash, Debug, Clone, Copy)]\npub enum CompletionIntent {\n    /// The user intends to 'commit' this result, if possible\n    /// completion confirmations should run side effects\n    Complete,\n    /// The user intends to continue 'composing' this completion\n    /// completion confirmations should not run side effects and\n    /// let the user continue composing their action\n    Compose,\n}\n\nimpl CompletionIntent {\n    pub fn is_complete(&self) -> bool {\n        self == &Self::Complete\n    }\n\n    pub fn is_compose(&self) -> bool {\n        self == &Self::Compose\n    }\n}\n\n/// A completion provided by a language server\n#[derive(Clone)]\npub struct Completion {\n    /// The range of the buffer that will be replaced.\n    pub old_range: Range<Anchor>,\n    /// The new text that will be inserted.\n    pub new_text: String,\n    /// A label for this completion that is shown in the menu.\n    pub label: CodeLabel,\n    /// The id of the language server that produced this completion.\n    pub server_id: LanguageServerId,\n    /// The documentation for this completion.\n    pub documentation: Option<CompletionDocumentation>,\n    /// The raw completion provided by the language server.\n    pub lsp_completion: lsp::CompletionItem,\n    /// Whether this completion has been resolved, to ensure it happens once per completion.\n    pub resolved: bool,\n    /// An optional callback to invoke when this completion is confirmed.\n    /// Returns, whether new completions should be retriggered after the current one.\n    /// If `true` is returned, the editor will show a new completion menu after this completion is confirmed.\n    /// if no confirmation is provided or `false` is returned, the completion will be committed.\n    pub confirm: Option<Arc<dyn Send + Sync + Fn(CompletionIntent, &mut Window, &mut App) -> bool>>,\n}\n\nimpl std::fmt::Debug for Completion {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        f.debug_struct(\"Completion\")\n            .field(\"old_range\", &self.old_range)\n            .field(\"new_text\", &self.new_text)\n            .field(\"label\", &self.label)\n            .field(\"server_id\", &self.server_id)\n            .field(\"documentation\", &self.documentation)\n            .field(\"lsp_completion\", &self.lsp_completion)\n            .finish()\n    }\n}\n\n/// A completion provided by a language server\n#[derive(Clone, Debug)]\npub(crate) struct CoreCompletion {\n    old_range: Range<Anchor>,\n    new_text: String,\n    server_id: LanguageServerId,\n    lsp_completion: lsp::CompletionItem,\n    resolved: bool,\n}\n\n/// A code action provided by a language server.\n#[derive(Clone, Debug)]\npub struct CodeAction {\n    /// The id of the language server that produced this code action.\n    pub server_id: LanguageServerId,\n    /// The range of the buffer where this code action is applicable.\n    pub range: Range<Anchor>,\n    /// The raw code action provided by the language server.\n    pub lsp_action: lsp::CodeAction,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub enum ResolveState {\n    Resolved,\n    CanResolve(LanguageServerId, Option<lsp::LSPAny>),\n    Resolving,\n}\n\nimpl InlayHint {\n    pub fn text(&self) -> String {\n        match &self.label {\n            InlayHintLabel::String(s) => s.to_owned(),\n            InlayHintLabel::LabelParts(parts) => parts.iter().map(|part| &part.value).join(\"\"),\n        }\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub enum InlayHintLabel {\n    String(String),\n    LabelParts(Vec<InlayHintLabelPart>),\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub struct InlayHintLabelPart {\n    pub value: String,\n    pub tooltip: Option<InlayHintLabelPartTooltip>,\n    pub location: Option<(LanguageServerId, lsp::Location)>,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub enum InlayHintTooltip {\n    String(String),\n    MarkupContent(MarkupContent),\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub enum InlayHintLabelPartTooltip {\n    String(String),\n    MarkupContent(MarkupContent),\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub struct MarkupContent {\n    pub kind: HoverBlockKind,\n    pub value: String,\n}\n\n#[derive(Debug, Clone)]\npub struct LocationLink {\n    pub origin: Option<Location>,\n    pub target: Location,\n}\n\n#[derive(Debug)]\npub struct DocumentHighlight {\n    pub range: Range<language::Anchor>,\n    pub kind: DocumentHighlightKind,\n}\n\n#[derive(Clone, Debug)]\npub struct Symbol {\n    pub language_server_name: LanguageServerName,\n    pub source_worktree_id: WorktreeId,\n    pub path: ProjectPath,\n    pub label: CodeLabel,\n    pub name: String,\n    pub kind: lsp::SymbolKind,\n    pub range: Range<Unclipped<PointUtf16>>,\n    pub signature: [u8; 32],\n}\n\n#[derive(Clone, Debug, PartialEq)]\npub struct HoverBlock {\n    pub text: String,\n    pub kind: HoverBlockKind,\n}\n\n#[derive(Clone, Debug, PartialEq, Eq)]\npub enum HoverBlockKind {\n    PlainText,\n    Markdown,\n    Code { language: String },\n}\n\n#[derive(Debug, Clone)]\npub struct Hover {\n    pub contents: Vec<HoverBlock>,\n    pub range: Option<Range<language::Anchor>>,\n    pub language: Option<Arc<Language>>,\n}\n\nimpl Hover {\n    pub fn is_empty(&self) -> bool {\n        self.contents.iter().all(|block| block.text.is_empty())\n    }\n}\n\nenum EntitySubscription {\n    Project(PendingEntitySubscription<Project>),\n    BufferStore(PendingEntitySubscription<BufferStore>),\n    WorktreeStore(PendingEntitySubscription<WorktreeStore>),\n    LspStore(PendingEntitySubscription<LspStore>),\n    SettingsObserver(PendingEntitySubscription<SettingsObserver>),\n}\n\n#[derive(Clone)]\npub enum DirectoryLister {\n    Project(Entity<Project>),\n    Local(Arc<dyn Fs>),\n}\n\nimpl DirectoryLister {\n    pub fn is_local(&self, cx: &App) -> bool {\n        match self {\n            DirectoryLister::Local(_) => true,\n            DirectoryLister::Project(project) => project.read(cx).is_local(),\n        }\n    }\n\n    pub fn resolve_tilde<'a>(&self, path: &'a String, cx: &App) -> Cow<'a, str> {\n        if self.is_local(cx) {\n            shellexpand::tilde(path)\n        } else {\n            Cow::from(path)\n        }\n    }\n\n    pub fn default_query(&self, cx: &mut App) -> String {\n        if let DirectoryLister::Project(project) = self {\n            if let Some(worktree) = project.read(cx).visible_worktrees(cx).next() {\n                return worktree.read(cx).abs_path().to_string_lossy().to_string();\n            }\n        };\n        \"~/\".to_string()\n    }\n\n    pub fn list_directory(&self, path: String, cx: &mut App) -> Task<Result<Vec<PathBuf>>> {\n        match self {\n            DirectoryLister::Project(project) => {\n                project.update(cx, |project, cx| project.list_directory(path, cx))\n            }\n            DirectoryLister::Local(fs) => {\n                let fs = fs.clone();\n                cx.background_executor().spawn(async move {\n                    let mut results = vec![];\n                    let expanded = shellexpand::tilde(&path);\n                    let query = Path::new(expanded.as_ref());\n                    let mut response = fs.read_dir(query).await?;\n                    while let Some(path) = response.next().await {\n                        if let Some(file_name) = path?.file_name() {\n                            results.push(PathBuf::from(file_name.to_os_string()));\n                        }\n                    }\n                    Ok(results)\n                })\n            }\n        }\n    }\n}\n\n#[cfg(any(test, feature = \"test-support\"))]\npub const DEFAULT_COMPLETION_CONTEXT: CompletionContext = CompletionContext {\n    trigger_kind: lsp::CompletionTriggerKind::INVOKED,\n    trigger_character: None,\n};\n\nimpl Project {\n    pub fn init_settings(cx: &mut App) {\n        WorktreeSettings::register(cx);\n        ProjectSettings::register(cx);\n    }\n\n    pub fn init(client: &Arc<Client>, cx: &mut App) {\n        connection_manager::init(client.clone(), cx);\n        Self::init_settings(cx);\n\n        let client: AnyProtoClient = client.clone().into();\n        client.add_entity_message_handler(Self::handle_add_collaborator);\n        client.add_entity_message_handler(Self::handle_update_project_collaborator);\n        client.add_entity_message_handler(Self::handle_remove_collaborator);\n        client.add_entity_message_handler(Self::handle_update_project);\n        client.add_entity_message_handler(Self::handle_unshare_project);\n        client.add_entity_request_handler(Self::handle_update_buffer);\n        client.add_entity_message_handler(Self::handle_update_worktree);\n        client.add_entity_request_handler(Self::handle_synchronize_buffers);\n\n        client.add_entity_request_handler(Self::handle_search_candidate_buffers);\n        client.add_entity_request_handler(Self::handle_open_buffer_by_id);\n        client.add_entity_request_handler(Self::handle_open_buffer_by_path);\n        client.add_entity_request_handler(Self::handle_open_new_buffer);\n        client.add_entity_message_handler(Self::handle_create_buffer_for_peer);\n\n        client.add_entity_request_handler(Self::handle_stage);\n        client.add_entity_request_handler(Self::handle_unstage);\n        client.add_entity_request_handler(Self::handle_commit);\n        client.add_entity_request_handler(Self::handle_open_commit_message_buffer);\n\n        WorktreeStore::init(&client);\n        BufferStore::init(&client);\n        LspStore::init(&client);\n        SettingsObserver::init(&client);\n        TaskStore::init(Some(&client));\n        ToolchainStore::init(&client);\n    }\n\n    pub fn local(\n        client: Arc<Client>,\n        node: NodeRuntime,\n        user_store: Entity<UserStore>,\n        languages: Arc<LanguageRegistry>,\n        fs: Arc<dyn Fs>,\n        env: Option<HashMap<String, String>>,\n        cx: &mut App,\n    ) -> Entity<Self> {\n        cx.new(|cx: &mut Context<Self>| {\n            let (tx, rx) = mpsc::unbounded();\n            cx.spawn(move |this, cx| Self::send_buffer_ordered_messages(this, rx, cx))\n                .detach();\n            let snippets = SnippetProvider::new(fs.clone(), BTreeSet::from_iter([]), cx);\n            let worktree_store = cx.new(|_| WorktreeStore::local(false, fs.clone()));\n            cx.subscribe(&worktree_store, Self::on_worktree_store_event)\n                .detach();\n\n            let buffer_store = cx.new(|cx| BufferStore::local(worktree_store.clone(), cx));\n            cx.subscribe(&buffer_store, Self::on_buffer_store_event)\n                .detach();\n\n            let image_store = cx.new(|cx| ImageStore::local(worktree_store.clone(), cx));\n            cx.subscribe(&image_store, Self::on_image_store_event)\n                .detach();\n\n            let prettier_store = cx.new(|cx| {\n                PrettierStore::new(\n                    node.clone(),\n                    fs.clone(),\n                    languages.clone(),\n                    worktree_store.clone(),\n                    cx,\n                )\n            });\n\n            let environment = ProjectEnvironment::new(&worktree_store, env, cx);\n            let toolchain_store = cx.new(|cx| {\n                ToolchainStore::local(\n                    languages.clone(),\n                    worktree_store.clone(),\n                    environment.clone(),\n                    cx,\n                )\n            });\n            let task_store = cx.new(|cx| {\n                TaskStore::local(\n                    fs.clone(),\n                    buffer_store.downgrade(),\n                    worktree_store.clone(),\n                    toolchain_store.read(cx).as_language_toolchain_store(),\n                    environment.clone(),\n                    cx,\n                )\n            });\n\n            let settings_observer = cx.new(|cx| {\n                SettingsObserver::new_local(\n                    fs.clone(),\n                    worktree_store.clone(),\n                    task_store.clone(),\n                    cx,\n                )\n            });\n            cx.subscribe(&settings_observer, Self::on_settings_observer_event)\n                .detach();\n\n            let lsp_store = cx.new(|cx| {\n                LspStore::new_local(\n                    buffer_store.clone(),\n                    worktree_store.clone(),\n                    prettier_store.clone(),\n                    toolchain_store.clone(),\n                    environment.clone(),\n                    languages.clone(),\n                    client.http_client(),\n                    fs.clone(),\n                    cx,\n                )\n            });\n\n            let git_state = cx.new(|cx| GitState::new(&worktree_store, None, None, cx));\n\n            cx.subscribe(&lsp_store, Self::on_lsp_store_event).detach();\n\n            Self {\n                buffer_ordered_messages_tx: tx,\n                collaborators: Default::default(),\n                worktree_store,\n                buffer_store,\n                image_store,\n                lsp_store,\n                join_project_response_message_id: 0,\n                client_state: ProjectClientState::Local,\n                git_state,\n                client_subscriptions: Vec::new(),\n                _subscriptions: vec![cx.on_release(Self::release)],\n                active_entry: None,\n                snippets,\n                languages,\n                client,\n                task_store,\n                user_store,\n                settings_observer,\n                fs,\n                ssh_client: None,\n                buffers_needing_diff: Default::default(),\n                git_diff_debouncer: DebouncedDelay::new(),\n                terminals: Terminals {\n                    local_handles: Vec::new(),\n                },\n                node: Some(node),\n                search_history: Self::new_search_history(),\n                environment,\n                remotely_created_models: Default::default(),\n\n                search_included_history: Self::new_search_history(),\n                search_excluded_history: Self::new_search_history(),\n\n                toolchain_store: Some(toolchain_store),\n            }\n        })\n    }\n\n    pub fn ssh(\n        ssh: Entity<SshRemoteClient>,\n        client: Arc<Client>,\n        node: NodeRuntime,\n        user_store: Entity<UserStore>,\n        languages: Arc<LanguageRegistry>,\n        fs: Arc<dyn Fs>,\n        cx: &mut App,\n    ) -> Entity<Self> {\n        cx.new(|cx: &mut Context<Self>| {\n            let (tx, rx) = mpsc::unbounded();\n            cx.spawn(move |this, cx| Self::send_buffer_ordered_messages(this, rx, cx))\n                .detach();\n            let global_snippets_dir = paths::config_dir().join(\"snippets\");\n            let snippets =\n                SnippetProvider::new(fs.clone(), BTreeSet::from_iter([global_snippets_dir]), cx);\n\n            let ssh_proto = ssh.read(cx).proto_client();\n            let worktree_store =\n                cx.new(|_| WorktreeStore::remote(false, ssh_proto.clone(), SSH_PROJECT_ID));\n            cx.subscribe(&worktree_store, Self::on_worktree_store_event)\n                .detach();\n\n            let buffer_store = cx.new(|cx| {\n                BufferStore::remote(\n                    worktree_store.clone(),\n                    ssh.read(cx).proto_client(),\n                    SSH_PROJECT_ID,\n                    cx,\n                )\n            });\n            let image_store = cx.new(|cx| {\n                ImageStore::remote(\n                    worktree_store.clone(),\n                    ssh.read(cx).proto_client(),\n                    SSH_PROJECT_ID,\n                    cx,\n                )\n            });\n            cx.subscribe(&buffer_store, Self::on_buffer_store_event)\n                .detach();\n            let toolchain_store = cx\n                .new(|cx| ToolchainStore::remote(SSH_PROJECT_ID, ssh.read(cx).proto_client(), cx));\n            let task_store = cx.new(|cx| {\n                TaskStore::remote(\n                    fs.clone(),\n                    buffer_store.downgrade(),\n                    worktree_store.clone(),\n                    toolchain_store.read(cx).as_language_toolchain_store(),\n                    ssh.read(cx).proto_client(),\n                    SSH_PROJECT_ID,\n                    cx,\n                )\n            });\n\n            let settings_observer = cx.new(|cx| {\n                SettingsObserver::new_remote(worktree_store.clone(), task_store.clone(), cx)\n            });\n            cx.subscribe(&settings_observer, Self::on_settings_observer_event)\n                .detach();\n\n            let environment = ProjectEnvironment::new(&worktree_store, None, cx);\n\n            let lsp_store = cx.new(|cx| {\n                LspStore::new_remote(\n                    buffer_store.clone(),\n                    worktree_store.clone(),\n                    Some(toolchain_store.clone()),\n                    languages.clone(),\n                    ssh_proto.clone(),\n                    SSH_PROJECT_ID,\n                    fs.clone(),\n                    cx,\n                )\n            });\n            cx.subscribe(&lsp_store, Self::on_lsp_store_event).detach();\n\n            let git_state = cx.new(|cx| {\n                GitState::new(\n                    &worktree_store,\n                    Some(ssh_proto.clone()),\n                    Some(ProjectId(SSH_PROJECT_ID)),\n                    cx,\n                )\n            });\n\n            cx.subscribe(&ssh, Self::on_ssh_event).detach();\n            cx.observe(&ssh, |_, _, cx| cx.notify()).detach();\n\n            let this = Self {\n                buffer_ordered_messages_tx: tx,\n                collaborators: Default::default(),\n                worktree_store,\n                buffer_store,\n                image_store,\n                lsp_store,\n                join_project_response_message_id: 0,\n                client_state: ProjectClientState::Local,\n                git_state,\n                client_subscriptions: Vec::new(),\n                _subscriptions: vec![\n                    cx.on_release(Self::release),\n                    cx.on_app_quit(|this, cx| {\n                        let shutdown = this.ssh_client.take().and_then(|client| {\n                            client\n                                .read(cx)\n                                .shutdown_processes(Some(proto::ShutdownRemoteServer {}))\n                        });\n\n                        cx.background_executor().spawn(async move {\n                            if let Some(shutdown) = shutdown {\n                                shutdown.await;\n                            }\n                        })\n                    }),\n                ],\n                active_entry: None,\n                snippets,\n                languages,\n                client,\n                task_store,\n                user_store,\n                settings_observer,\n                fs,\n                ssh_client: Some(ssh.clone()),\n                buffers_needing_diff: Default::default(),\n                git_diff_debouncer: DebouncedDelay::new(),\n                terminals: Terminals {\n                    local_handles: Vec::new(),\n                },\n                node: Some(node),\n                search_history: Self::new_search_history(),\n                environment,\n                remotely_created_models: Default::default(),\n\n                search_included_history: Self::new_search_history(),\n                search_excluded_history: Self::new_search_history(),\n\n                toolchain_store: Some(toolchain_store),\n            };\n\n            // ssh -> local machine handlers\n            let ssh = ssh.read(cx);\n            ssh.subscribe_to_entity(SSH_PROJECT_ID, &cx.entity());\n            ssh.subscribe_to_entity(SSH_PROJECT_ID, &this.buffer_store);\n            ssh.subscribe_to_entity(SSH_PROJECT_ID, &this.worktree_store);\n            ssh.subscribe_to_entity(SSH_PROJECT_ID, &this.lsp_store);\n            ssh.subscribe_to_entity(SSH_PROJECT_ID, &this.settings_observer);\n\n            ssh_proto.add_entity_message_handler(Self::handle_create_buffer_for_peer);\n            ssh_proto.add_entity_message_handler(Self::handle_update_worktree);\n            ssh_proto.add_entity_message_handler(Self::handle_update_project);\n            ssh_proto.add_entity_message_handler(Self::handle_toast);\n            ssh_proto.add_entity_request_handler(Self::handle_language_server_prompt_request);\n            ssh_proto.add_entity_message_handler(Self::handle_hide_toast);\n            ssh_proto.add_entity_request_handler(Self::handle_update_buffer_from_ssh);\n            BufferStore::init(&ssh_proto);\n            LspStore::init(&ssh_proto);\n            SettingsObserver::init(&ssh_proto);\n            TaskStore::init(Some(&ssh_proto));\n            ToolchainStore::init(&ssh_proto);\n\n            this\n        })\n    }\n\n    pub async fn remote(\n        remote_id: u64,\n        client: Arc<Client>,\n        user_store: Entity<UserStore>,\n        languages: Arc<LanguageRegistry>,\n        fs: Arc<dyn Fs>,\n        cx: AsyncApp,\n    ) -> Result<Entity<Self>> {\n        let project =\n            Self::in_room(remote_id, client, user_store, languages, fs, cx.clone()).await?;\n        cx.update(|cx| {\n            connection_manager::Manager::global(cx).update(cx, |manager, cx| {\n                manager.maintain_project_connection(&project, cx)\n            })\n        })?;\n        Ok(project)\n    }\n\n    pub async fn in_room(\n        remote_id: u64,\n        client: Arc<Client>,\n        user_store: Entity<UserStore>,\n        languages: Arc<LanguageRegistry>,\n        fs: Arc<dyn Fs>,\n        cx: AsyncApp,\n    ) -> Result<Entity<Self>> {\n        client.authenticate_and_connect(true, &cx).await?;\n\n        let subscriptions = [\n            EntitySubscription::Project(client.subscribe_to_entity::<Self>(remote_id)?),\n            EntitySubscription::BufferStore(client.subscribe_to_entity::<BufferStore>(remote_id)?),\n            EntitySubscription::WorktreeStore(\n                client.subscribe_to_entity::<WorktreeStore>(remote_id)?,\n            ),\n            EntitySubscription::LspStore(client.subscribe_to_entity::<LspStore>(remote_id)?),\n            EntitySubscription::SettingsObserver(\n                client.subscribe_to_entity::<SettingsObserver>(remote_id)?,\n            ),\n        ];\n        let response = client\n            .request_envelope(proto::JoinProject {\n                project_id: remote_id,\n            })\n            .await?;\n        Self::from_join_project_response(\n            response,\n            subscriptions,\n            client,\n            false,\n            user_store,\n            languages,\n            fs,\n            cx,\n        )\n        .await\n    }\n\n    #[allow(clippy::too_many_arguments)]\n    async fn from_join_project_response(\n        response: TypedEnvelope<proto::JoinProjectResponse>,\n        subscriptions: [EntitySubscription; 5],\n        client: Arc<Client>,\n        run_tasks: bool,\n        user_store: Entity<UserStore>,\n        languages: Arc<LanguageRegistry>,\n        fs: Arc<dyn Fs>,\n        mut cx: AsyncApp,\n    ) -> Result<Entity<Self>> {\n        let remote_id = response.payload.project_id;\n        let role = response.payload.role();\n\n        let worktree_store = cx.new(|_| {\n            WorktreeStore::remote(true, client.clone().into(), response.payload.project_id)\n        })?;\n        let buffer_store = cx.new(|cx| {\n            BufferStore::remote(worktree_store.clone(), client.clone().into(), remote_id, cx)\n        })?;\n        let image_store = cx.new(|cx| {\n            ImageStore::remote(worktree_store.clone(), client.clone().into(), remote_id, cx)\n        })?;\n\n        let lsp_store = cx.new(|cx| {\n            let mut lsp_store = LspStore::new_remote(\n                buffer_store.clone(),\n                worktree_store.clone(),\n                None,\n                languages.clone(),\n                client.clone().into(),\n                remote_id,\n                fs.clone(),\n                cx,\n            );\n            lsp_store.set_language_server_statuses_from_proto(response.payload.language_servers);\n            lsp_store\n        })?;\n\n        let task_store = cx.new(|cx| {\n            if run_tasks {\n                TaskStore::remote(\n                    fs.clone(),\n                    buffer_store.downgrade(),\n                    worktree_store.clone(),\n                    Arc::new(EmptyToolchainStore),\n                    client.clone().into(),\n                    remote_id,\n                    cx,\n                )\n            } else {\n                TaskStore::Noop\n            }\n        })?;\n\n        let settings_observer = cx.new(|cx| {\n            SettingsObserver::new_remote(worktree_store.clone(), task_store.clone(), cx)\n        })?;\n\n        let git_state = cx.new(|cx| {\n            GitState::new(\n                &worktree_store,\n                Some(client.clone().into()),\n                Some(ProjectId(remote_id)),\n                cx,\n            )\n        })?;\n\n        let this = cx.new(|cx| {\n            let replica_id = response.payload.replica_id as ReplicaId;\n\n            let snippets = SnippetProvider::new(fs.clone(), BTreeSet::from_iter([]), cx);\n\n            let mut worktrees = Vec::new();\n            for worktree in response.payload.worktrees {\n                let worktree =\n                    Worktree::remote(remote_id, replica_id, worktree, client.clone().into(), cx);\n                worktrees.push(worktree);\n            }\n\n            let (tx, rx) = mpsc::unbounded();\n            cx.spawn(move |this, cx| Self::send_buffer_ordered_messages(this, rx, cx))\n                .detach();\n\n            cx.subscribe(&worktree_store, Self::on_worktree_store_event)\n                .detach();\n\n            cx.subscribe(&buffer_store, Self::on_buffer_store_event)\n                .detach();\n            cx.subscribe(&lsp_store, Self::on_lsp_store_event).detach();\n            cx.subscribe(&settings_observer, Self::on_settings_observer_event)\n                .detach();\n\n            let mut this = Self {\n                buffer_ordered_messages_tx: tx,\n                buffer_store: buffer_store.clone(),\n                image_store,\n                worktree_store: worktree_store.clone(),\n                lsp_store: lsp_store.clone(),\n                active_entry: None,\n                collaborators: Default::default(),\n                join_project_response_message_id: response.message_id,\n                languages,\n                user_store: user_store.clone(),\n                task_store,\n                snippets,\n                fs,\n                ssh_client: None,\n                settings_observer: settings_observer.clone(),\n                client_subscriptions: Default::default(),\n                _subscriptions: vec![cx.on_release(Self::release)],\n                client: client.clone(),\n                client_state: ProjectClientState::Remote {\n                    sharing_has_stopped: false,\n                    capability: Capability::ReadWrite,\n                    remote_id,\n                    replica_id,\n                },\n                git_state,\n                buffers_needing_diff: Default::default(),\n                git_diff_debouncer: DebouncedDelay::new(),\n                terminals: Terminals {\n                    local_handles: Vec::new(),\n                },\n                node: None,\n                search_history: Self::new_search_history(),\n                search_included_history: Self::new_search_history(),\n                search_excluded_history: Self::new_search_history(),\n                environment: ProjectEnvironment::new(&worktree_store, None, cx),\n                remotely_created_models: Arc::new(Mutex::new(RemotelyCreatedModels::default())),\n                toolchain_store: None,\n            };\n            this.set_role(role, cx);\n            for worktree in worktrees {\n                this.add_worktree(&worktree, cx);\n            }\n            this\n        })?;\n\n        let subscriptions = subscriptions\n            .into_iter()\n            .map(|s| match s {\n                EntitySubscription::BufferStore(subscription) => {\n                    subscription.set_entity(&buffer_store, &mut cx)\n                }\n                EntitySubscription::WorktreeStore(subscription) => {\n                    subscription.set_entity(&worktree_store, &mut cx)\n                }\n                EntitySubscription::SettingsObserver(subscription) => {\n                    subscription.set_entity(&settings_observer, &mut cx)\n                }\n                EntitySubscription::Project(subscription) => {\n                    subscription.set_entity(&this, &mut cx)\n                }\n                EntitySubscription::LspStore(subscription) => {\n                    subscription.set_entity(&lsp_store, &mut cx)\n                }\n            })\n            .collect::<Vec<_>>();\n\n        let user_ids = response\n            .payload\n            .collaborators\n            .iter()\n            .map(|peer| peer.user_id)\n            .collect();\n        user_store\n            .update(&mut cx, |user_store, cx| user_store.get_users(user_ids, cx))?\n            .await?;\n\n        this.update(&mut cx, |this, cx| {\n            this.set_collaborators_from_proto(response.payload.collaborators, cx)?;\n            this.client_subscriptions.extend(subscriptions);\n            anyhow::Ok(())\n        })??;\n\n        Ok(this)\n    }\n\n    fn new_search_history() -> SearchHistory {\n        SearchHistory::new(\n            Some(MAX_PROJECT_SEARCH_HISTORY_SIZE),\n            search_history::QueryInsertionBehavior::AlwaysInsert,\n        )\n    }\n\n    fn release(&mut self, cx: &mut App) {\n        if let Some(client) = self.ssh_client.take() {\n            let shutdown = client\n                .read(cx)\n                .shutdown_processes(Some(proto::ShutdownRemoteServer {}));\n\n            cx.background_executor()\n                .spawn(async move {\n                    if let Some(shutdown) = shutdown {\n                        shutdown.await;\n                    }\n                })\n                .detach()\n        }\n\n        match &self.client_state {\n            ProjectClientState::Local => {}\n            ProjectClientState::Shared { .. } => {\n                let _ = self.unshare_internal(cx);\n            }\n            ProjectClientState::Remote { remote_id, .. } => {\n                let _ = self.client.send(proto::LeaveProject {\n                    project_id: *remote_id,\n                });\n                self.disconnected_from_host_internal(cx);\n            }\n        }\n    }\n\n    #[cfg(any(test, feature = \"test-support\"))]\n    pub async fn example(\n        root_paths: impl IntoIterator<Item = &Path>,\n        cx: &mut AsyncApp,\n    ) -> Entity<Project> {\n        use clock::FakeSystemClock;\n\n        let fs = Arc::new(RealFs::default());\n        let languages = LanguageRegistry::test(cx.background_executor().clone());\n        let clock = Arc::new(FakeSystemClock::new());\n        let http_client = http_client::FakeHttpClient::with_404_response();\n        let client = cx\n            .update(|cx| client::Client::new(clock, http_client.clone(), cx))\n            .unwrap();\n        let user_store = cx.new(|cx| UserStore::new(client.clone(), cx)).unwrap();\n        let project = cx\n            .update(|cx| {\n                Project::local(\n                    client,\n                    node_runtime::NodeRuntime::unavailable(),\n                    user_store,\n                    Arc::new(languages),\n                    fs,\n                    None,\n                    cx,\n                )\n            })\n            .unwrap();\n        for path in root_paths {\n            let (tree, _) = project\n                .update(cx, |project, cx| {\n                    project.find_or_create_worktree(path, true, cx)\n                })\n                .unwrap()\n                .await\n                .unwrap();\n            tree.update(cx, |tree, _| tree.as_local().unwrap().scan_complete())\n                .unwrap()\n                .await;\n        }\n        project\n    }\n\n    #[cfg(any(test, feature = \"test-support\"))]\n    pub async fn test(\n        fs: Arc<dyn Fs>,\n        root_paths: impl IntoIterator<Item = &Path>,\n        cx: &mut gpui::TestAppContext,\n    ) -> Entity<Project> {\n        use clock::FakeSystemClock;\n\n        let languages = LanguageRegistry::test(cx.executor());\n        let clock = Arc::new(FakeSystemClock::new());\n        let http_client = http_client::FakeHttpClient::with_404_response();\n        let client = cx.update(|cx| client::Client::new(clock, http_client.clone(), cx));\n        let user_store = cx.new(|cx| UserStore::new(client.clone(), cx));\n        let project = cx.update(|cx| {\n            Project::local(\n                client,\n                node_runtime::NodeRuntime::unavailable(),\n                user_store,\n                Arc::new(languages),\n                fs,\n                None,\n                cx,\n            )\n        });\n        for path in root_paths {\n            let (tree, _) = project\n                .update(cx, |project, cx| {\n                    project.find_or_create_worktree(path, true, cx)\n                })\n                .await\n                .unwrap();\n\n            tree.update(cx, |tree, _| tree.as_local().unwrap().scan_complete())\n                .await;\n        }\n        project\n    }\n\n    pub fn lsp_store(&self) -> Entity<LspStore> {\n        self.lsp_store.clone()\n    }\n\n    pub fn worktree_store(&self) -> Entity<WorktreeStore> {\n        self.worktree_store.clone()\n    }\n\n    pub fn buffer_for_id(&self, remote_id: BufferId, cx: &App) -> Option<Entity<Buffer>> {\n        self.buffer_store.read(cx).get(remote_id)\n    }\n\n    pub fn languages(&self) -> &Arc<LanguageRegistry> {\n        &self.languages\n    }\n\n    pub fn client(&self) -> Arc<Client> {\n        self.client.clone()\n    }\n\n    pub fn ssh_client(&self) -> Option<Entity<SshRemoteClient>> {\n        self.ssh_client.clone()\n    }\n\n    pub fn user_store(&self) -> Entity<UserStore> {\n        self.user_store.clone()\n    }\n\n    pub fn node_runtime(&self) -> Option<&NodeRuntime> {\n        self.node.as_ref()\n    }\n\n    pub fn opened_buffers(&self, cx: &App) -> Vec<Entity<Buffer>> {\n        self.buffer_store.read(cx).buffers().collect()\n    }\n\n    pub fn environment(&self) -> &Entity<ProjectEnvironment> {\n        &self.environment\n    }\n\n    pub fn cli_environment(&self, cx: &App) -> Option<HashMap<String, String>> {\n        self.environment.read(cx).get_cli_environment()\n    }\n\n    pub fn shell_environment_errors<'a>(\n        &'a self,\n        cx: &'a App,\n    ) -> impl Iterator<Item = (&'a WorktreeId, &'a EnvironmentErrorMessage)> {\n        self.environment.read(cx).environment_errors()\n    }\n\n    pub fn remove_environment_error(&mut self, cx: &mut Context<Self>, worktree_id: WorktreeId) {\n        self.environment.update(cx, |environment, _| {\n            environment.remove_environment_error(worktree_id);\n        });\n    }\n\n    #[cfg(any(test, feature = \"test-support\"))]\n    pub fn has_open_buffer(&self, path: impl Into<ProjectPath>, cx: &App) -> bool {\n        self.buffer_store\n            .read(cx)\n            .get_by_path(&path.into(), cx)\n            .is_some()\n    }\n\n    pub fn fs(&self) -> &Arc<dyn Fs> {\n        &self.fs\n    }\n\n    pub fn remote_id(&self) -> Option<u64> {\n        match self.client_state {\n            ProjectClientState::Local => None,\n            ProjectClientState::Shared { remote_id, .. }\n            | ProjectClientState::Remote { remote_id, .. } => Some(remote_id),\n        }\n    }\n\n    pub fn supports_terminal(&self, _cx: &App) -> bool {\n        if self.is_local() {\n            return true;\n        }\n        if self.is_via_ssh() {\n            return true;\n        }\n\n        return false;\n    }\n\n    pub fn ssh_connection_string(&self, cx: &App) -> Option<SharedString> {\n        if let Some(ssh_state) = &self.ssh_client {\n            return Some(ssh_state.read(cx).connection_string().into());\n        }\n\n        return None;\n    }\n\n    pub fn ssh_connection_state(&self, cx: &App) -> Option<remote::ConnectionState> {\n        self.ssh_client\n            .as_ref()\n            .map(|ssh| ssh.read(cx).connection_state())\n    }\n\n    pub fn ssh_connection_options(&self, cx: &App) -> Option<SshConnectionOptions> {\n        self.ssh_client\n            .as_ref()\n            .map(|ssh| ssh.read(cx).connection_options())\n    }\n\n    pub fn replica_id(&self) -> ReplicaId {\n        match self.client_state {\n            ProjectClientState::Remote { replica_id, .. } => replica_id,\n            _ => {\n                if self.ssh_client.is_some() {\n                    1\n                } else {\n                    0\n                }\n            }\n        }\n    }\n\n    pub fn task_store(&self) -> &Entity<TaskStore> {\n        &self.task_store\n    }\n\n    pub fn snippets(&self) -> &Entity<SnippetProvider> {\n        &self.snippets\n    }\n\n    pub fn search_history(&self, kind: SearchInputKind) -> &SearchHistory {\n        match kind {\n            SearchInputKind::Query => &self.search_history,\n            SearchInputKind::Include => &self.search_included_history,\n            SearchInputKind::Exclude => &self.search_excluded_history,\n        }\n    }\n\n    pub fn search_history_mut(&mut self, kind: SearchInputKind) -> &mut SearchHistory {\n        match kind {\n            SearchInputKind::Query => &mut self.search_history,\n            SearchInputKind::Include => &mut self.search_included_history,\n            SearchInputKind::Exclude => &mut self.search_excluded_history,\n        }\n    }\n\n    pub fn collaborators(&self) -> &HashMap<proto::PeerId, Collaborator> {\n        &self.collaborators\n    }\n\n    pub fn host(&self) -> Option<&Collaborator> {\n        self.collaborators.values().find(|c| c.is_host)\n    }\n\n    pub fn set_worktrees_reordered(&mut self, worktrees_reordered: bool, cx: &mut App) {\n        self.worktree_store.update(cx, |store, _| {\n            store.set_worktrees_reordered(worktrees_reordered);\n        });\n    }\n\n    /// Collect all worktrees, including ones that don't appear in the project panel\n    pub fn worktrees<'a>(\n        &self,\n        cx: &'a App,\n    ) -> impl 'a + DoubleEndedIterator<Item = Entity<Worktree>> {\n        self.worktree_store.read(cx).worktrees()\n    }\n\n    /// Collect all user-visible worktrees, the ones that appear in the project panel.\n    pub fn visible_worktrees<'a>(\n        &'a self,\n        cx: &'a App,\n    ) -> impl 'a + DoubleEndedIterator<Item = Entity<Worktree>> {\n        self.worktree_store.read(cx).visible_worktrees(cx)\n    }\n\n    pub fn worktree_root_names<'a>(&'a self, cx: &'a App) -> impl Iterator<Item = &'a str> {\n        self.visible_worktrees(cx)\n            .map(|tree| tree.read(cx).root_name())\n    }\n\n    pub fn worktree_for_id(&self, id: WorktreeId, cx: &App) -> Option<Entity<Worktree>> {\n        self.worktree_store.read(cx).worktree_for_id(id, cx)\n    }\n\n    pub fn worktree_for_entry(\n        &self,\n        entry_id: ProjectEntryId,\n        cx: &App,\n    ) -> Option<Entity<Worktree>> {\n        self.worktree_store\n            .read(cx)\n            .worktree_for_entry(entry_id, cx)\n    }\n\n    pub fn worktree_id_for_entry(&self, entry_id: ProjectEntryId, cx: &App) -> Option<WorktreeId> {\n        self.worktree_for_entry(entry_id, cx)\n            .map(|worktree| worktree.read(cx).id())\n    }\n\n    /// Checks if the entry is the root of a worktree.\n    pub fn entry_is_worktree_root(&self, entry_id: ProjectEntryId, cx: &App) -> bool {\n        self.worktree_for_entry(entry_id, cx)\n            .map(|worktree| {\n                worktree\n                    .read(cx)\n                    .root_entry()\n                    .is_some_and(|e| e.id == entry_id)\n            })\n            .unwrap_or(false)\n    }\n\n    pub fn project_path_git_status(\n        &self,\n        project_path: &ProjectPath,\n        cx: &App,\n    ) -> Option<FileStatus> {\n        self.worktree_for_id(project_path.worktree_id, cx)\n            .and_then(|worktree| worktree.read(cx).status_for_file(&project_path.path))\n    }\n\n    pub fn visibility_for_paths(&self, paths: &[PathBuf], cx: &App) -> Option<bool> {\n        paths\n            .iter()\n            .map(|path| self.visibility_for_path(path, cx))\n            .max()\n            .flatten()\n    }\n\n    pub fn visibility_for_path(&self, path: &Path, cx: &App) -> Option<bool> {\n        self.worktrees(cx)\n            .filter_map(|worktree| {\n                let worktree = worktree.read(cx);\n                worktree\n                    .as_local()?\n                    .contains_abs_path(path)\n                    .then(|| worktree.is_visible())\n            })\n            .max()\n    }\n\n    pub fn create_entry(\n        &mut self,\n        project_path: impl Into<ProjectPath>,\n        is_directory: bool,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<CreatedEntry>> {\n        let project_path = project_path.into();\n        let Some(worktree) = self.worktree_for_id(project_path.worktree_id, cx) else {\n            return Task::ready(Err(anyhow!(format!(\n                \"No worktree for path {project_path:?}\"\n            ))));\n        };\n        worktree.update(cx, |worktree, cx| {\n            worktree.create_entry(project_path.path, is_directory, cx)\n        })\n    }\n\n    pub fn copy_entry(\n        &mut self,\n        entry_id: ProjectEntryId,\n        relative_worktree_source_path: Option<PathBuf>,\n        new_path: impl Into<Arc<Path>>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Option<Entry>>> {\n        let Some(worktree) = self.worktree_for_entry(entry_id, cx) else {\n            return Task::ready(Ok(None));\n        };\n        worktree.update(cx, |worktree, cx| {\n            worktree.copy_entry(entry_id, relative_worktree_source_path, new_path, cx)\n        })\n    }\n\n    /// Renames the project entry with given `entry_id`.\n    ///\n    /// `new_path` is a relative path to worktree root.\n    /// If root entry is renamed then its new root name is used instead.\n    pub fn rename_entry(\n        &mut self,\n        entry_id: ProjectEntryId,\n        new_path: impl Into<Arc<Path>>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<CreatedEntry>> {\n        let worktree_store = self.worktree_store.read(cx);\n        let new_path = new_path.into();\n        let Some((worktree, old_path, is_dir)) = worktree_store\n            .worktree_and_entry_for_id(entry_id, cx)\n            .map(|(worktree, entry)| (worktree, entry.path.clone(), entry.is_dir()))\n        else {\n            return Task::ready(Err(anyhow!(format!(\"No worktree for entry {entry_id:?}\"))));\n        };\n\n        let worktree_id = worktree.read(cx).id();\n        let is_root_entry = self.entry_is_worktree_root(entry_id, cx);\n\n        let lsp_store = self.lsp_store().downgrade();\n        cx.spawn(|_, mut cx| async move {\n            let (old_abs_path, new_abs_path) = {\n                let root_path = worktree.update(&mut cx, |this, _| this.abs_path())?;\n                let new_abs_path = if is_root_entry {\n                    root_path.parent().unwrap().join(&new_path)\n                } else {\n                    root_path.join(&new_path)\n                };\n                (root_path.join(&old_path), new_abs_path)\n            };\n            LspStore::will_rename_entry(\n                lsp_store.clone(),\n                worktree_id,\n                &old_abs_path,\n                &new_abs_path,\n                is_dir,\n                cx.clone(),\n            )\n            .await;\n\n            let entry = worktree\n                .update(&mut cx, |worktree, cx| {\n                    worktree.rename_entry(entry_id, new_path.clone(), cx)\n                })?\n                .await?;\n\n            lsp_store\n                .update(&mut cx, |this, _| {\n                    this.did_rename_entry(worktree_id, &old_abs_path, &new_abs_path, is_dir);\n                })\n                .ok();\n            Ok(entry)\n        })\n    }\n\n    pub fn delete_entry(\n        &mut self,\n        entry_id: ProjectEntryId,\n        trash: bool,\n        cx: &mut Context<Self>,\n    ) -> Option<Task<Result<()>>> {\n        let worktree = self.worktree_for_entry(entry_id, cx)?;\n        cx.emit(Event::DeletedEntry(worktree.read(cx).id(), entry_id));\n        worktree.update(cx, |worktree, cx| {\n            worktree.delete_entry(entry_id, trash, cx)\n        })\n    }\n\n    pub fn expand_entry(\n        &mut self,\n        worktree_id: WorktreeId,\n        entry_id: ProjectEntryId,\n        cx: &mut Context<Self>,\n    ) -> Option<Task<Result<()>>> {\n        let worktree = self.worktree_for_id(worktree_id, cx)?;\n        worktree.update(cx, |worktree, cx| worktree.expand_entry(entry_id, cx))\n    }\n\n    pub fn expand_all_for_entry(\n        &mut self,\n        worktree_id: WorktreeId,\n        entry_id: ProjectEntryId,\n        cx: &mut Context<Self>,\n    ) -> Option<Task<Result<()>>> {\n        let worktree = self.worktree_for_id(worktree_id, cx)?;\n        let task = worktree.update(cx, |worktree, cx| {\n            worktree.expand_all_for_entry(entry_id, cx)\n        });\n        Some(cx.spawn(|this, mut cx| async move {\n            task.ok_or_else(|| anyhow!(\"no task\"))?.await?;\n            this.update(&mut cx, |_, cx| {\n                cx.emit(Event::ExpandedAllForEntry(worktree_id, entry_id));\n            })?;\n            Ok(())\n        }))\n    }\n\n    pub fn shared(&mut self, project_id: u64, cx: &mut Context<Self>) -> Result<()> {\n        if !matches!(self.client_state, ProjectClientState::Local) {\n            return Err(anyhow!(\"project was already shared\"));\n        }\n\n        self.client_subscriptions.extend([\n            self.client\n                .subscribe_to_entity(project_id)?\n                .set_entity(&cx.entity(), &mut cx.to_async()),\n            self.client\n                .subscribe_to_entity(project_id)?\n                .set_entity(&self.worktree_store, &mut cx.to_async()),\n            self.client\n                .subscribe_to_entity(project_id)?\n                .set_entity(&self.buffer_store, &mut cx.to_async()),\n            self.client\n                .subscribe_to_entity(project_id)?\n                .set_entity(&self.lsp_store, &mut cx.to_async()),\n            self.client\n                .subscribe_to_entity(project_id)?\n                .set_entity(&self.settings_observer, &mut cx.to_async()),\n        ]);\n\n        self.buffer_store.update(cx, |buffer_store, cx| {\n            buffer_store.shared(project_id, self.client.clone().into(), cx)\n        });\n        self.worktree_store.update(cx, |worktree_store, cx| {\n            worktree_store.shared(project_id, self.client.clone().into(), cx);\n        });\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.shared(project_id, self.client.clone().into(), cx)\n        });\n        self.task_store.update(cx, |task_store, cx| {\n            task_store.shared(project_id, self.client.clone().into(), cx);\n        });\n        self.settings_observer.update(cx, |settings_observer, cx| {\n            settings_observer.shared(project_id, self.client.clone().into(), cx)\n        });\n\n        self.client_state = ProjectClientState::Shared {\n            remote_id: project_id,\n        };\n\n        cx.emit(Event::RemoteIdChanged(Some(project_id)));\n        cx.notify();\n        Ok(())\n    }\n\n    pub fn reshared(\n        &mut self,\n        message: proto::ResharedProject,\n        cx: &mut Context<Self>,\n    ) -> Result<()> {\n        self.buffer_store\n            .update(cx, |buffer_store, _| buffer_store.forget_shared_buffers());\n        self.set_collaborators_from_proto(message.collaborators, cx)?;\n\n        self.worktree_store.update(cx, |worktree_store, cx| {\n            worktree_store.send_project_updates(cx);\n        });\n        cx.notify();\n        cx.emit(Event::Reshared);\n        Ok(())\n    }\n\n    pub fn rejoined(\n        &mut self,\n        message: proto::RejoinedProject,\n        message_id: u32,\n        cx: &mut Context<Self>,\n    ) -> Result<()> {\n        cx.update_global::<SettingsStore, _>(|store, cx| {\n            self.worktree_store.update(cx, |worktree_store, cx| {\n                for worktree in worktree_store.worktrees() {\n                    store\n                        .clear_local_settings(worktree.read(cx).id(), cx)\n                        .log_err();\n                }\n            });\n        });\n\n        self.join_project_response_message_id = message_id;\n        self.set_worktrees_from_proto(message.worktrees, cx)?;\n        self.set_collaborators_from_proto(message.collaborators, cx)?;\n        self.lsp_store.update(cx, |lsp_store, _| {\n            lsp_store.set_language_server_statuses_from_proto(message.language_servers)\n        });\n        self.enqueue_buffer_ordered_message(BufferOrderedMessage::Resync)\n            .unwrap();\n        cx.emit(Event::Rejoined);\n        cx.notify();\n        Ok(())\n    }\n\n    pub fn unshare(&mut self, cx: &mut Context<Self>) -> Result<()> {\n        self.unshare_internal(cx)?;\n        cx.notify();\n        Ok(())\n    }\n\n    fn unshare_internal(&mut self, cx: &mut App) -> Result<()> {\n        if self.is_via_collab() {\n            return Err(anyhow!(\"attempted to unshare a remote project\"));\n        }\n\n        if let ProjectClientState::Shared { remote_id, .. } = self.client_state {\n            self.client_state = ProjectClientState::Local;\n            self.collaborators.clear();\n            self.client_subscriptions.clear();\n            self.worktree_store.update(cx, |store, cx| {\n                store.unshared(cx);\n            });\n            self.buffer_store.update(cx, |buffer_store, cx| {\n                buffer_store.forget_shared_buffers();\n                buffer_store.unshared(cx)\n            });\n            self.task_store.update(cx, |task_store, cx| {\n                task_store.unshared(cx);\n            });\n            self.settings_observer.update(cx, |settings_observer, cx| {\n                settings_observer.unshared(cx);\n            });\n\n            self.client\n                .send(proto::UnshareProject {\n                    project_id: remote_id,\n                })\n                .ok();\n            Ok(())\n        } else {\n            Err(anyhow!(\"attempted to unshare an unshared project\"))\n        }\n    }\n\n    pub fn disconnected_from_host(&mut self, cx: &mut Context<Self>) {\n        if self.is_disconnected(cx) {\n            return;\n        }\n        self.disconnected_from_host_internal(cx);\n        cx.emit(Event::DisconnectedFromHost);\n        cx.notify();\n    }\n\n    pub fn set_role(&mut self, role: proto::ChannelRole, cx: &mut Context<Self>) {\n        let new_capability =\n            if role == proto::ChannelRole::Member || role == proto::ChannelRole::Admin {\n                Capability::ReadWrite\n            } else {\n                Capability::ReadOnly\n            };\n        if let ProjectClientState::Remote { capability, .. } = &mut self.client_state {\n            if *capability == new_capability {\n                return;\n            }\n\n            *capability = new_capability;\n            for buffer in self.opened_buffers(cx) {\n                buffer.update(cx, |buffer, cx| buffer.set_capability(new_capability, cx));\n            }\n        }\n    }\n\n    fn disconnected_from_host_internal(&mut self, cx: &mut App) {\n        if let ProjectClientState::Remote {\n            sharing_has_stopped,\n            ..\n        } = &mut self.client_state\n        {\n            *sharing_has_stopped = true;\n            self.collaborators.clear();\n            self.worktree_store.update(cx, |store, cx| {\n                store.disconnected_from_host(cx);\n            });\n            self.buffer_store.update(cx, |buffer_store, cx| {\n                buffer_store.disconnected_from_host(cx)\n            });\n            self.lsp_store\n                .update(cx, |lsp_store, _cx| lsp_store.disconnected_from_host());\n        }\n    }\n\n    pub fn close(&mut self, cx: &mut Context<Self>) {\n        cx.emit(Event::Closed);\n    }\n\n    pub fn is_disconnected(&self, cx: &App) -> bool {\n        match &self.client_state {\n            ProjectClientState::Remote {\n                sharing_has_stopped,\n                ..\n            } => *sharing_has_stopped,\n            ProjectClientState::Local if self.is_via_ssh() => self.ssh_is_disconnected(cx),\n            _ => false,\n        }\n    }\n\n    fn ssh_is_disconnected(&self, cx: &App) -> bool {\n        self.ssh_client\n            .as_ref()\n            .map(|ssh| ssh.read(cx).is_disconnected())\n            .unwrap_or(false)\n    }\n\n    pub fn capability(&self) -> Capability {\n        match &self.client_state {\n            ProjectClientState::Remote { capability, .. } => *capability,\n            ProjectClientState::Shared { .. } | ProjectClientState::Local => Capability::ReadWrite,\n        }\n    }\n\n    pub fn is_read_only(&self, cx: &App) -> bool {\n        self.is_disconnected(cx) || self.capability() == Capability::ReadOnly\n    }\n\n    pub fn is_local(&self) -> bool {\n        match &self.client_state {\n            ProjectClientState::Local | ProjectClientState::Shared { .. } => {\n                self.ssh_client.is_none()\n            }\n            ProjectClientState::Remote { .. } => false,\n        }\n    }\n\n    pub fn is_via_ssh(&self) -> bool {\n        match &self.client_state {\n            ProjectClientState::Local | ProjectClientState::Shared { .. } => {\n                self.ssh_client.is_some()\n            }\n            ProjectClientState::Remote { .. } => false,\n        }\n    }\n\n    pub fn is_via_collab(&self) -> bool {\n        match &self.client_state {\n            ProjectClientState::Local | ProjectClientState::Shared { .. } => false,\n            ProjectClientState::Remote { .. } => true,\n        }\n    }\n\n    pub fn create_buffer(&mut self, cx: &mut Context<Self>) -> Task<Result<Entity<Buffer>>> {\n        self.buffer_store\n            .update(cx, |buffer_store, cx| buffer_store.create_buffer(cx))\n    }\n\n    pub fn create_local_buffer(\n        &mut self,\n        text: &str,\n        language: Option<Arc<Language>>,\n        cx: &mut Context<Self>,\n    ) -> Entity<Buffer> {\n        if self.is_via_collab() || self.is_via_ssh() {\n            panic!(\"called create_local_buffer on a remote project\")\n        }\n        self.buffer_store.update(cx, |buffer_store, cx| {\n            buffer_store.create_local_buffer(text, language, cx)\n        })\n    }\n\n    pub fn open_path(\n        &mut self,\n        path: ProjectPath,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<(Option<ProjectEntryId>, AnyEntity)>> {\n        let task = self.open_buffer(path.clone(), cx);\n        cx.spawn(move |_, cx| async move {\n            let buffer = task.await?;\n            let project_entry_id = buffer.read_with(&cx, |buffer, cx| {\n                File::from_dyn(buffer.file()).and_then(|file| file.project_entry_id(cx))\n            })?;\n\n            let buffer: &AnyEntity = &buffer;\n            Ok((project_entry_id, buffer.clone()))\n        })\n    }\n\n    pub fn open_local_buffer(\n        &mut self,\n        abs_path: impl AsRef<Path>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Entity<Buffer>>> {\n        if let Some((worktree, relative_path)) = self.find_worktree(abs_path.as_ref(), cx) {\n            self.open_buffer((worktree.read(cx).id(), relative_path), cx)\n        } else {\n            Task::ready(Err(anyhow!(\"no such path\")))\n        }\n    }\n\n    #[cfg(any(test, feature = \"test-support\"))]\n    pub fn open_local_buffer_with_lsp(\n        &mut self,\n        abs_path: impl AsRef<Path>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<(Entity<Buffer>, lsp_store::OpenLspBufferHandle)>> {\n        if let Some((worktree, relative_path)) = self.find_worktree(abs_path.as_ref(), cx) {\n            self.open_buffer_with_lsp((worktree.read(cx).id(), relative_path), cx)\n        } else {\n            Task::ready(Err(anyhow!(\"no such path\")))\n        }\n    }\n\n    pub fn open_buffer(\n        &mut self,\n        path: impl Into<ProjectPath>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Entity<Buffer>>> {\n        if self.is_disconnected(cx) {\n            return Task::ready(Err(anyhow!(ErrorCode::Disconnected)));\n        }\n\n        self.buffer_store.update(cx, |buffer_store, cx| {\n            buffer_store.open_buffer(path.into(), cx)\n        })\n    }\n\n    #[cfg(any(test, feature = \"test-support\"))]\n    pub fn open_buffer_with_lsp(\n        &mut self,\n        path: impl Into<ProjectPath>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<(Entity<Buffer>, lsp_store::OpenLspBufferHandle)>> {\n        let buffer = self.open_buffer(path, cx);\n        let lsp_store = self.lsp_store().clone();\n        cx.spawn(|_, mut cx| async move {\n            let buffer = buffer.await?;\n            let handle = lsp_store.update(&mut cx, |lsp_store, cx| {\n                lsp_store.register_buffer_with_language_servers(&buffer, cx)\n            })?;\n            Ok((buffer, handle))\n        })\n    }\n\n    pub fn open_unstaged_diff(\n        &mut self,\n        buffer: Entity<Buffer>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Entity<BufferDiff>>> {\n        if self.is_disconnected(cx) {\n            return Task::ready(Err(anyhow!(ErrorCode::Disconnected)));\n        }\n\n        self.buffer_store.update(cx, |buffer_store, cx| {\n            buffer_store.open_unstaged_diff(buffer, cx)\n        })\n    }\n\n    pub fn open_uncommitted_diff(\n        &mut self,\n        buffer: Entity<Buffer>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Entity<BufferDiff>>> {\n        if self.is_disconnected(cx) {\n            return Task::ready(Err(anyhow!(ErrorCode::Disconnected)));\n        }\n\n        self.buffer_store.update(cx, |buffer_store, cx| {\n            buffer_store.open_uncommitted_diff(buffer, cx)\n        })\n    }\n\n    pub fn open_buffer_by_id(\n        &mut self,\n        id: BufferId,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Entity<Buffer>>> {\n        if let Some(buffer) = self.buffer_for_id(id, cx) {\n            Task::ready(Ok(buffer))\n        } else if self.is_local() || self.is_via_ssh() {\n            Task::ready(Err(anyhow!(\"buffer {} does not exist\", id)))\n        } else if let Some(project_id) = self.remote_id() {\n            let request = self.client.request(proto::OpenBufferById {\n                project_id,\n                id: id.into(),\n            });\n            cx.spawn(move |project, mut cx| async move {\n                let buffer_id = BufferId::new(request.await?.buffer_id)?;\n                project\n                    .update(&mut cx, |project, cx| {\n                        project.buffer_store.update(cx, |buffer_store, cx| {\n                            buffer_store.wait_for_remote_buffer(buffer_id, cx)\n                        })\n                    })?\n                    .await\n            })\n        } else {\n            Task::ready(Err(anyhow!(\"cannot open buffer while disconnected\")))\n        }\n    }\n\n    pub fn save_buffers(\n        &self,\n        buffers: HashSet<Entity<Buffer>>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<()>> {\n        cx.spawn(move |this, mut cx| async move {\n            let save_tasks = buffers.into_iter().filter_map(|buffer| {\n                this.update(&mut cx, |this, cx| this.save_buffer(buffer, cx))\n                    .ok()\n            });\n            try_join_all(save_tasks).await?;\n            Ok(())\n        })\n    }\n\n    pub fn save_buffer(&self, buffer: Entity<Buffer>, cx: &mut Context<Self>) -> Task<Result<()>> {\n        self.buffer_store\n            .update(cx, |buffer_store, cx| buffer_store.save_buffer(buffer, cx))\n    }\n\n    pub fn save_buffer_as(\n        &mut self,\n        buffer: Entity<Buffer>,\n        path: ProjectPath,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<()>> {\n        self.buffer_store.update(cx, |buffer_store, cx| {\n            buffer_store.save_buffer_as(buffer.clone(), path, cx)\n        })\n    }\n\n    pub fn get_open_buffer(&self, path: &ProjectPath, cx: &App) -> Option<Entity<Buffer>> {\n        self.buffer_store.read(cx).get_by_path(path, cx)\n    }\n\n    fn register_buffer(&mut self, buffer: &Entity<Buffer>, cx: &mut Context<Self>) -> Result<()> {\n        {\n            let mut remotely_created_models = self.remotely_created_models.lock();\n            if remotely_created_models.retain_count > 0 {\n                remotely_created_models.buffers.push(buffer.clone())\n            }\n        }\n\n        self.request_buffer_diff_recalculation(buffer, cx);\n\n        cx.subscribe(buffer, |this, buffer, event, cx| {\n            this.on_buffer_event(buffer, event, cx);\n        })\n        .detach();\n\n        Ok(())\n    }\n\n    pub fn open_image(\n        &mut self,\n        path: impl Into<ProjectPath>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Entity<ImageItem>>> {\n        if self.is_disconnected(cx) {\n            return Task::ready(Err(anyhow!(ErrorCode::Disconnected)));\n        }\n\n        let open_image_task = self.image_store.update(cx, |image_store, cx| {\n            image_store.open_image(path.into(), cx)\n        });\n\n        let weak_project = cx.entity().downgrade();\n        cx.spawn(move |_, mut cx| async move {\n            let image_item = open_image_task.await?;\n            let project = weak_project\n                .upgrade()\n                .ok_or_else(|| anyhow!(\"Project dropped\"))?;\n\n            let metadata =\n                ImageItem::load_image_metadata(image_item.clone(), project, &mut cx).await?;\n            image_item.update(&mut cx, |image_item, cx| {\n                image_item.image_metadata = Some(metadata);\n                cx.emit(ImageItemEvent::MetadataUpdated);\n            })?;\n\n            Ok(image_item)\n        })\n    }\n\n    async fn send_buffer_ordered_messages(\n        this: WeakEntity<Self>,\n        rx: UnboundedReceiver<BufferOrderedMessage>,\n        mut cx: AsyncApp,\n    ) -> Result<()> {\n        const MAX_BATCH_SIZE: usize = 128;\n\n        let mut operations_by_buffer_id = HashMap::default();\n        async fn flush_operations(\n            this: &WeakEntity<Project>,\n            operations_by_buffer_id: &mut HashMap<BufferId, Vec<proto::Operation>>,\n            needs_resync_with_host: &mut bool,\n            is_local: bool,\n            cx: &mut AsyncApp,\n        ) -> Result<()> {\n            for (buffer_id, operations) in operations_by_buffer_id.drain() {\n                let request = this.update(cx, |this, _| {\n                    let project_id = this.remote_id()?;\n                    Some(this.client.request(proto::UpdateBuffer {\n                        buffer_id: buffer_id.into(),\n                        project_id,\n                        operations,\n                    }))\n                })?;\n                if let Some(request) = request {\n                    if request.await.is_err() && !is_local {\n                        *needs_resync_with_host = true;\n                        break;\n                    }\n                }\n            }\n            Ok(())\n        }\n\n        let mut needs_resync_with_host = false;\n        let mut changes = rx.ready_chunks(MAX_BATCH_SIZE);\n\n        while let Some(changes) = changes.next().await {\n            let is_local = this.update(&mut cx, |this, _| this.is_local())?;\n\n            for change in changes {\n                match change {\n                    BufferOrderedMessage::Operation {\n                        buffer_id,\n                        operation,\n                    } => {\n                        if needs_resync_with_host {\n                            continue;\n                        }\n\n                        operations_by_buffer_id\n                            .entry(buffer_id)\n                            .or_insert(Vec::new())\n                            .push(operation);\n                    }\n\n                    BufferOrderedMessage::Resync => {\n                        operations_by_buffer_id.clear();\n                        if this\n                            .update(&mut cx, |this, cx| this.synchronize_remote_buffers(cx))?\n                            .await\n                            .is_ok()\n                        {\n                            needs_resync_with_host = false;\n                        }\n                    }\n\n                    BufferOrderedMessage::LanguageServerUpdate {\n                        language_server_id,\n                        message,\n                    } => {\n                        flush_operations(\n                            &this,\n                            &mut operations_by_buffer_id,\n                            &mut needs_resync_with_host,\n                            is_local,\n                            &mut cx,\n                        )\n                        .await?;\n\n                        this.update(&mut cx, |this, _| {\n                            if let Some(project_id) = this.remote_id() {\n                                this.client\n                                    .send(proto::UpdateLanguageServer {\n                                        project_id,\n                                        language_server_id: language_server_id.0 as u64,\n                                        variant: Some(message),\n                                    })\n                                    .log_err();\n                            }\n                        })?;\n                    }\n                }\n            }\n\n            flush_operations(\n                &this,\n                &mut operations_by_buffer_id,\n                &mut needs_resync_with_host,\n                is_local,\n                &mut cx,\n            )\n            .await?;\n        }\n\n        Ok(())\n    }\n\n    fn on_buffer_store_event(\n        &mut self,\n        _: Entity<BufferStore>,\n        event: &BufferStoreEvent,\n        cx: &mut Context<Self>,\n    ) {\n        match event {\n            BufferStoreEvent::BufferAdded(buffer) => {\n                self.register_buffer(buffer, cx).log_err();\n            }\n            BufferStoreEvent::BufferChangedFilePath { .. } => {}\n            BufferStoreEvent::BufferDropped(buffer_id) => {\n                if let Some(ref ssh_client) = self.ssh_client {\n                    ssh_client\n                        .read(cx)\n                        .proto_client()\n                        .send(proto::CloseBuffer {\n                            project_id: 0,\n                            buffer_id: buffer_id.to_proto(),\n                        })\n                        .log_err();\n                }\n            }\n        }\n    }\n\n    fn on_image_store_event(\n        &mut self,\n        _: Entity<ImageStore>,\n        event: &ImageStoreEvent,\n        cx: &mut Context<Self>,\n    ) {\n        match event {\n            ImageStoreEvent::ImageAdded(image) => {\n                cx.subscribe(image, |this, image, event, cx| {\n                    this.on_image_event(image, event, cx);\n                })\n                .detach();\n            }\n        }\n    }\n\n    fn on_lsp_store_event(\n        &mut self,\n        _: Entity<LspStore>,\n        event: &LspStoreEvent,\n        cx: &mut Context<Self>,\n    ) {\n        match event {\n            LspStoreEvent::DiagnosticsUpdated {\n                language_server_id,\n                path,\n            } => cx.emit(Event::DiagnosticsUpdated {\n                path: path.clone(),\n                language_server_id: *language_server_id,\n            }),\n            LspStoreEvent::LanguageServerAdded(language_server_id, name, worktree_id) => cx.emit(\n                Event::LanguageServerAdded(*language_server_id, name.clone(), *worktree_id),\n            ),\n            LspStoreEvent::LanguageServerRemoved(language_server_id) => {\n                cx.emit(Event::LanguageServerRemoved(*language_server_id))\n            }\n            LspStoreEvent::LanguageServerLog(server_id, log_type, string) => cx.emit(\n                Event::LanguageServerLog(*server_id, log_type.clone(), string.clone()),\n            ),\n            LspStoreEvent::LanguageDetected {\n                buffer,\n                new_language,\n            } => {\n                let Some(_) = new_language else {\n                    cx.emit(Event::LanguageNotFound(buffer.clone()));\n                    return;\n                };\n            }\n            LspStoreEvent::RefreshInlayHints => cx.emit(Event::RefreshInlayHints),\n            LspStoreEvent::LanguageServerPrompt(prompt) => {\n                cx.emit(Event::LanguageServerPrompt(prompt.clone()))\n            }\n            LspStoreEvent::DiskBasedDiagnosticsStarted { language_server_id } => {\n                cx.emit(Event::DiskBasedDiagnosticsStarted {\n                    language_server_id: *language_server_id,\n                });\n            }\n            LspStoreEvent::DiskBasedDiagnosticsFinished { language_server_id } => {\n                cx.emit(Event::DiskBasedDiagnosticsFinished {\n                    language_server_id: *language_server_id,\n                });\n            }\n            LspStoreEvent::LanguageServerUpdate {\n                language_server_id,\n                message,\n            } => {\n                if self.is_local() {\n                    self.enqueue_buffer_ordered_message(\n                        BufferOrderedMessage::LanguageServerUpdate {\n                            language_server_id: *language_server_id,\n                            message: message.clone(),\n                        },\n                    )\n                    .ok();\n                }\n            }\n            LspStoreEvent::Notification(message) => cx.emit(Event::Toast {\n                notification_id: \"lsp\".into(),\n                message: message.clone(),\n            }),\n            LspStoreEvent::SnippetEdit {\n                buffer_id,\n                edits,\n                most_recent_edit,\n            } => {\n                if most_recent_edit.replica_id == self.replica_id() {\n                    cx.emit(Event::SnippetEdit(*buffer_id, edits.clone()))\n                }\n            }\n        }\n    }\n\n    fn on_ssh_event(\n        &mut self,\n        _: Entity<SshRemoteClient>,\n        event: &remote::SshRemoteEvent,\n        cx: &mut Context<Self>,\n    ) {\n        match event {\n            remote::SshRemoteEvent::Disconnected => {\n                // if self.is_via_ssh() {\n                // self.collaborators.clear();\n                self.worktree_store.update(cx, |store, cx| {\n                    store.disconnected_from_host(cx);\n                });\n                self.buffer_store.update(cx, |buffer_store, cx| {\n                    buffer_store.disconnected_from_host(cx)\n                });\n                self.lsp_store.update(cx, |lsp_store, _cx| {\n                    lsp_store.disconnected_from_ssh_remote()\n                });\n                cx.emit(Event::DisconnectedFromSshRemote);\n            }\n        }\n    }\n\n    fn on_settings_observer_event(\n        &mut self,\n        _: Entity<SettingsObserver>,\n        event: &SettingsObserverEvent,\n        cx: &mut Context<Self>,\n    ) {\n        match event {\n            SettingsObserverEvent::LocalSettingsUpdated(result) => match result {\n                Err(InvalidSettingsError::LocalSettings { message, path }) => {\n                    let message =\n                        format!(\"Failed to set local settings in {:?}:\\n{}\", path, message);\n                    cx.emit(Event::Toast {\n                        notification_id: \"local-settings\".into(),\n                        message,\n                    });\n                }\n                Ok(_) => cx.emit(Event::HideToast {\n                    notification_id: \"local-settings\".into(),\n                }),\n                Err(_) => {}\n            },\n        }\n    }\n\n    fn on_worktree_store_event(\n        &mut self,\n        _: Entity<WorktreeStore>,\n        event: &WorktreeStoreEvent,\n        cx: &mut Context<Self>,\n    ) {\n        match event {\n            WorktreeStoreEvent::WorktreeAdded(worktree) => {\n                self.on_worktree_added(worktree, cx);\n                cx.emit(Event::WorktreeAdded(worktree.read(cx).id()));\n            }\n            WorktreeStoreEvent::WorktreeRemoved(_, id) => {\n                cx.emit(Event::WorktreeRemoved(*id));\n            }\n            WorktreeStoreEvent::WorktreeReleased(_, id) => {\n                self.on_worktree_released(*id, cx);\n            }\n            WorktreeStoreEvent::WorktreeOrderChanged => cx.emit(Event::WorktreeOrderChanged),\n            WorktreeStoreEvent::WorktreeUpdateSent(_) => {}\n            WorktreeStoreEvent::WorktreeUpdatedEntries(worktree_id, changes) => {\n                self.client()\n                    .telemetry()\n                    .report_discovered_project_events(*worktree_id, changes);\n                cx.emit(Event::WorktreeUpdatedEntries(*worktree_id, changes.clone()))\n            }\n            WorktreeStoreEvent::WorktreeUpdatedGitRepositories(worktree_id) => {\n                cx.emit(Event::WorktreeUpdatedGitRepositories(*worktree_id))\n            }\n            WorktreeStoreEvent::WorktreeDeletedEntry(worktree_id, id) => {\n                cx.emit(Event::DeletedEntry(*worktree_id, *id))\n            }\n        }\n    }\n\n    fn on_worktree_added(&mut self, worktree: &Entity<Worktree>, cx: &mut Context<Self>) {\n        {\n            let mut remotely_created_models = self.remotely_created_models.lock();\n            if remotely_created_models.retain_count > 0 {\n                remotely_created_models.worktrees.push(worktree.clone())\n            }\n        }\n        cx.observe(worktree, |_, _, cx| cx.notify()).detach();\n        cx.notify();\n    }\n\n    fn on_worktree_released(&mut self, id_to_remove: WorktreeId, cx: &mut Context<Self>) {\n        if let Some(ssh) = &self.ssh_client {\n            ssh.read(cx)\n                .proto_client()\n                .send(proto::RemoveWorktree {\n                    worktree_id: id_to_remove.to_proto(),\n                })\n                .log_err();\n        }\n\n        cx.notify();\n    }\n\n    fn on_buffer_event(\n        &mut self,\n        buffer: Entity<Buffer>,\n        event: &BufferEvent,\n        cx: &mut Context<Self>,\n    ) -> Option<()> {\n        if matches!(event, BufferEvent::Edited { .. } | BufferEvent::Reloaded) {\n            self.request_buffer_diff_recalculation(&buffer, cx);\n        }\n\n        let buffer_id = buffer.read(cx).remote_id();\n        match event {\n            BufferEvent::ReloadNeeded => {\n                if !self.is_via_collab() {\n                    self.reload_buffers([buffer.clone()].into_iter().collect(), true, cx)\n                        .detach_and_log_err(cx);\n                }\n            }\n            BufferEvent::Operation {\n                operation,\n                is_local: true,\n            } => {\n                let operation = language::proto::serialize_operation(operation);\n\n                if let Some(ssh) = &self.ssh_client {\n                    ssh.read(cx)\n                        .proto_client()\n                        .send(proto::UpdateBuffer {\n                            project_id: 0,\n                            buffer_id: buffer_id.to_proto(),\n                            operations: vec![operation.clone()],\n                        })\n                        .ok();\n                }\n\n                self.enqueue_buffer_ordered_message(BufferOrderedMessage::Operation {\n                    buffer_id,\n                    operation,\n                })\n                .ok();\n            }\n\n            _ => {}\n        }\n\n        None\n    }\n\n    fn on_image_event(\n        &mut self,\n        image: Entity<ImageItem>,\n        event: &ImageItemEvent,\n        cx: &mut Context<Self>,\n    ) -> Option<()> {\n        match event {\n            ImageItemEvent::ReloadNeeded => {\n                if !self.is_via_collab() {\n                    self.reload_images([image.clone()].into_iter().collect(), cx)\n                        .detach_and_log_err(cx);\n                }\n            }\n            _ => {}\n        }\n\n        None\n    }\n\n    fn request_buffer_diff_recalculation(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        cx: &mut Context<Self>,\n    ) {\n        self.buffers_needing_diff.insert(buffer.downgrade());\n        let first_insertion = self.buffers_needing_diff.len() == 1;\n\n        let settings = ProjectSettings::get_global(cx);\n        let delay = if let Some(delay) = settings.git.gutter_debounce {\n            delay\n        } else {\n            if first_insertion {\n                let this = cx.weak_entity();\n                cx.defer(move |cx| {\n                    if let Some(this) = this.upgrade() {\n                        this.update(cx, |this, cx| {\n                            this.recalculate_buffer_diffs(cx).detach();\n                        });\n                    }\n                });\n            }\n            return;\n        };\n\n        const MIN_DELAY: u64 = 50;\n        let delay = delay.max(MIN_DELAY);\n        let duration = Duration::from_millis(delay);\n\n        self.git_diff_debouncer\n            .fire_new(duration, cx, move |this, cx| {\n                this.recalculate_buffer_diffs(cx)\n            });\n    }\n\n    fn recalculate_buffer_diffs(&mut self, cx: &mut Context<Self>) -> Task<()> {\n        cx.spawn(move |this, mut cx| async move {\n            loop {\n                let task = this\n                    .update(&mut cx, |this, cx| {\n                        let buffers = this\n                            .buffers_needing_diff\n                            .drain()\n                            .filter_map(|buffer| buffer.upgrade())\n                            .collect::<Vec<_>>();\n                        if buffers.is_empty() {\n                            None\n                        } else {\n                            Some(this.buffer_store.update(cx, |buffer_store, cx| {\n                                buffer_store.recalculate_buffer_diffs(buffers, cx)\n                            }))\n                        }\n                    })\n                    .ok()\n                    .flatten();\n\n                if let Some(task) = task {\n                    task.await;\n                } else {\n                    break;\n                }\n            }\n        })\n    }\n\n    pub fn set_language_for_buffer(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        new_language: Arc<Language>,\n        cx: &mut Context<Self>,\n    ) {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.set_language_for_buffer(buffer, new_language, cx)\n        })\n    }\n\n    pub fn restart_language_servers_for_buffers(\n        &mut self,\n        buffers: impl IntoIterator<Item = Entity<Buffer>>,\n        cx: &mut Context<Self>,\n    ) {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.restart_language_servers_for_buffers(buffers, cx)\n        })\n    }\n\n    pub fn cancel_language_server_work_for_buffers(\n        &mut self,\n        buffers: impl IntoIterator<Item = Entity<Buffer>>,\n        cx: &mut Context<Self>,\n    ) {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.cancel_language_server_work_for_buffers(buffers, cx)\n        })\n    }\n\n    pub fn cancel_language_server_work(\n        &mut self,\n        server_id: LanguageServerId,\n        token_to_cancel: Option<String>,\n        cx: &mut Context<Self>,\n    ) {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.cancel_language_server_work(server_id, token_to_cancel, cx)\n        })\n    }\n\n    fn enqueue_buffer_ordered_message(&mut self, message: BufferOrderedMessage) -> Result<()> {\n        self.buffer_ordered_messages_tx\n            .unbounded_send(message)\n            .map_err(|e| anyhow!(e))\n    }\n\n    pub fn available_toolchains(\n        &self,\n        worktree_id: WorktreeId,\n        language_name: LanguageName,\n        cx: &App,\n    ) -> Task<Option<ToolchainList>> {\n        if let Some(toolchain_store) = self.toolchain_store.clone() {\n            cx.spawn(|cx| async move {\n                cx.update(|cx| {\n                    toolchain_store\n                        .read(cx)\n                        .list_toolchains(worktree_id, language_name, cx)\n                })\n                .ok()?\n                .await\n            })\n        } else {\n            Task::ready(None)\n        }\n    }\n\n    pub async fn toolchain_term(\n        languages: Arc<LanguageRegistry>,\n        language_name: LanguageName,\n    ) -> Option<SharedString> {\n        languages\n            .language_for_name(language_name.as_ref())\n            .await\n            .ok()?\n            .toolchain_lister()\n            .map(|lister| lister.term())\n    }\n\n    pub fn activate_toolchain(\n        &self,\n        worktree_id: WorktreeId,\n        toolchain: Toolchain,\n        cx: &mut App,\n    ) -> Task<Option<()>> {\n        let Some(toolchain_store) = self.toolchain_store.clone() else {\n            return Task::ready(None);\n        };\n        toolchain_store.update(cx, |this, cx| {\n            this.activate_toolchain(worktree_id, toolchain, cx)\n        })\n    }\n    pub fn active_toolchain(\n        &self,\n        worktree_id: WorktreeId,\n        language_name: LanguageName,\n        cx: &App,\n    ) -> Task<Option<Toolchain>> {\n        let Some(toolchain_store) = self.toolchain_store.clone() else {\n            return Task::ready(None);\n        };\n        toolchain_store\n            .read(cx)\n            .active_toolchain(worktree_id, language_name, cx)\n    }\n    pub fn language_server_statuses<'a>(\n        &'a self,\n        cx: &'a App,\n    ) -> impl DoubleEndedIterator<Item = (LanguageServerId, &'a LanguageServerStatus)> {\n        self.lsp_store.read(cx).language_server_statuses()\n    }\n\n    pub fn last_formatting_failure<'a>(&self, cx: &'a App) -> Option<&'a str> {\n        self.lsp_store.read(cx).last_formatting_failure()\n    }\n\n    pub fn reset_last_formatting_failure(&self, cx: &mut App) {\n        self.lsp_store\n            .update(cx, |store, _| store.reset_last_formatting_failure());\n    }\n\n    pub fn reload_buffers(\n        &self,\n        buffers: HashSet<Entity<Buffer>>,\n        push_to_history: bool,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<ProjectTransaction>> {\n        self.buffer_store.update(cx, |buffer_store, cx| {\n            buffer_store.reload_buffers(buffers, push_to_history, cx)\n        })\n    }\n\n    pub fn reload_images(\n        &self,\n        images: HashSet<Entity<ImageItem>>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<()>> {\n        self.image_store\n            .update(cx, |image_store, cx| image_store.reload_images(images, cx))\n    }\n\n    pub fn format(\n        &mut self,\n        buffers: HashSet<Entity<Buffer>>,\n        target: LspFormatTarget,\n        push_to_history: bool,\n        trigger: lsp_store::FormatTrigger,\n        cx: &mut Context<Project>,\n    ) -> Task<anyhow::Result<ProjectTransaction>> {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.format(buffers, target, push_to_history, trigger, cx)\n        })\n    }\n\n    #[inline(never)]\n    fn definition_impl(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        position: PointUtf16,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<LocationLink>>> {\n        self.request_lsp(\n            buffer.clone(),\n            LanguageServerToQuery::Primary,\n            GetDefinition { position },\n            cx,\n        )\n    }\n    pub fn definition<T: ToPointUtf16>(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        position: T,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<LocationLink>>> {\n        let position = position.to_point_utf16(buffer.read(cx));\n        self.definition_impl(buffer, position, cx)\n    }\n\n    fn declaration_impl(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        position: PointUtf16,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<LocationLink>>> {\n        self.request_lsp(\n            buffer.clone(),\n            LanguageServerToQuery::Primary,\n            GetDeclaration { position },\n            cx,\n        )\n    }\n\n    pub fn declaration<T: ToPointUtf16>(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        position: T,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<LocationLink>>> {\n        let position = position.to_point_utf16(buffer.read(cx));\n        self.declaration_impl(buffer, position, cx)\n    }\n\n    fn type_definition_impl(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        position: PointUtf16,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<LocationLink>>> {\n        self.request_lsp(\n            buffer.clone(),\n            LanguageServerToQuery::Primary,\n            GetTypeDefinition { position },\n            cx,\n        )\n    }\n\n    pub fn type_definition<T: ToPointUtf16>(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        position: T,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<LocationLink>>> {\n        let position = position.to_point_utf16(buffer.read(cx));\n        self.type_definition_impl(buffer, position, cx)\n    }\n\n    pub fn implementation<T: ToPointUtf16>(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        position: T,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<LocationLink>>> {\n        let position = position.to_point_utf16(buffer.read(cx));\n        self.request_lsp(\n            buffer.clone(),\n            LanguageServerToQuery::Primary,\n            GetImplementation { position },\n            cx,\n        )\n    }\n\n    pub fn references<T: ToPointUtf16>(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        position: T,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<Location>>> {\n        let position = position.to_point_utf16(buffer.read(cx));\n        self.request_lsp(\n            buffer.clone(),\n            LanguageServerToQuery::Primary,\n            GetReferences { position },\n            cx,\n        )\n    }\n\n    fn document_highlights_impl(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        position: PointUtf16,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<DocumentHighlight>>> {\n        self.request_lsp(\n            buffer.clone(),\n            LanguageServerToQuery::Primary,\n            GetDocumentHighlights { position },\n            cx,\n        )\n    }\n\n    pub fn document_highlights<T: ToPointUtf16>(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        position: T,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<DocumentHighlight>>> {\n        let position = position.to_point_utf16(buffer.read(cx));\n        self.document_highlights_impl(buffer, position, cx)\n    }\n\n    pub fn symbols(&self, query: &str, cx: &mut Context<Self>) -> Task<Result<Vec<Symbol>>> {\n        self.lsp_store\n            .update(cx, |lsp_store, cx| lsp_store.symbols(query, cx))\n    }\n\n    pub fn open_buffer_for_symbol(\n        &mut self,\n        symbol: &Symbol,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Entity<Buffer>>> {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.open_buffer_for_symbol(symbol, cx)\n        })\n    }\n\n    pub fn open_server_settings(&mut self, cx: &mut Context<Self>) -> Task<Result<Entity<Buffer>>> {\n        let guard = self.retain_remotely_created_models(cx);\n        let Some(ssh_client) = self.ssh_client.as_ref() else {\n            return Task::ready(Err(anyhow!(\"not an ssh project\")));\n        };\n\n        let proto_client = ssh_client.read(cx).proto_client();\n\n        cx.spawn(|project, mut cx| async move {\n            let buffer = proto_client\n                .request(proto::OpenServerSettings {\n                    project_id: SSH_PROJECT_ID,\n                })\n                .await?;\n\n            let buffer = project\n                .update(&mut cx, |project, cx| {\n                    project.buffer_store.update(cx, |buffer_store, cx| {\n                        anyhow::Ok(\n                            buffer_store\n                                .wait_for_remote_buffer(BufferId::new(buffer.buffer_id)?, cx),\n                        )\n                    })\n                })??\n                .await;\n\n            drop(guard);\n            buffer\n        })\n    }\n\n    pub fn open_local_buffer_via_lsp(\n        &mut self,\n        abs_path: lsp::Url,\n        language_server_id: LanguageServerId,\n        language_server_name: LanguageServerName,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Entity<Buffer>>> {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.open_local_buffer_via_lsp(\n                abs_path,\n                language_server_id,\n                language_server_name,\n                cx,\n            )\n        })\n    }\n\n    pub fn signature_help<T: ToPointUtf16>(\n        &self,\n        buffer: &Entity<Buffer>,\n        position: T,\n        cx: &mut Context<Self>,\n    ) -> Task<Vec<SignatureHelp>> {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.signature_help(buffer, position, cx)\n        })\n    }\n\n    pub fn hover<T: ToPointUtf16>(\n        &self,\n        buffer: &Entity<Buffer>,\n        position: T,\n        cx: &mut Context<Self>,\n    ) -> Task<Vec<Hover>> {\n        let position = position.to_point_utf16(buffer.read(cx));\n        self.lsp_store\n            .update(cx, |lsp_store, cx| lsp_store.hover(buffer, position, cx))\n    }\n\n    pub fn linked_edit(\n        &self,\n        buffer: &Entity<Buffer>,\n        position: Anchor,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<Range<Anchor>>>> {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.linked_edit(buffer, position, cx)\n        })\n    }\n\n    pub fn completions<T: ToOffset + ToPointUtf16>(\n        &self,\n        buffer: &Entity<Buffer>,\n        position: T,\n        context: CompletionContext,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<Completion>>> {\n        let position = position.to_point_utf16(buffer.read(cx));\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.completions(buffer, position, context, cx)\n        })\n    }\n\n    pub fn code_actions<T: Clone + ToOffset>(\n        &mut self,\n        buffer_handle: &Entity<Buffer>,\n        range: Range<T>,\n        kinds: Option<Vec<CodeActionKind>>,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<CodeAction>>> {\n        let buffer = buffer_handle.read(cx);\n        let range = buffer.anchor_before(range.start)..buffer.anchor_before(range.end);\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.code_actions(buffer_handle, range, kinds, cx)\n        })\n    }\n\n    pub fn apply_code_action(\n        &self,\n        buffer_handle: Entity<Buffer>,\n        action: CodeAction,\n        push_to_history: bool,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<ProjectTransaction>> {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.apply_code_action(buffer_handle, action, push_to_history, cx)\n        })\n    }\n\n    fn prepare_rename_impl(\n        &mut self,\n        buffer: Entity<Buffer>,\n        position: PointUtf16,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<PrepareRenameResponse>> {\n        self.request_lsp(\n            buffer,\n            LanguageServerToQuery::Primary,\n            PrepareRename { position },\n            cx,\n        )\n    }\n    pub fn prepare_rename<T: ToPointUtf16>(\n        &mut self,\n        buffer: Entity<Buffer>,\n        position: T,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<PrepareRenameResponse>> {\n        let position = position.to_point_utf16(buffer.read(cx));\n        self.prepare_rename_impl(buffer, position, cx)\n    }\n\n    pub fn perform_rename<T: ToPointUtf16>(\n        &mut self,\n        buffer: Entity<Buffer>,\n        position: T,\n        new_name: String,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<ProjectTransaction>> {\n        let push_to_history = true;\n        let position = position.to_point_utf16(buffer.read(cx));\n        self.request_lsp(\n            buffer,\n            LanguageServerToQuery::Primary,\n            PerformRename {\n                position,\n                new_name,\n                push_to_history,\n            },\n            cx,\n        )\n    }\n\n    pub fn on_type_format<T: ToPointUtf16>(\n        &mut self,\n        buffer: Entity<Buffer>,\n        position: T,\n        trigger: String,\n        push_to_history: bool,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Option<Transaction>>> {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.on_type_format(buffer, position, trigger, push_to_history, cx)\n        })\n    }\n\n    pub fn inlay_hints<T: ToOffset>(\n        &mut self,\n        buffer_handle: Entity<Buffer>,\n        range: Range<T>,\n        cx: &mut Context<Self>,\n    ) -> Task<anyhow::Result<Vec<InlayHint>>> {\n        let buffer = buffer_handle.read(cx);\n        let range = buffer.anchor_before(range.start)..buffer.anchor_before(range.end);\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.inlay_hints(buffer_handle, range, cx)\n        })\n    }\n\n    pub fn resolve_inlay_hint(\n        &self,\n        hint: InlayHint,\n        buffer_handle: Entity<Buffer>,\n        server_id: LanguageServerId,\n        cx: &mut Context<Self>,\n    ) -> Task<anyhow::Result<InlayHint>> {\n        self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.resolve_inlay_hint(hint, buffer_handle, server_id, cx)\n        })\n    }\n\n    pub fn search(&mut self, query: SearchQuery, cx: &mut Context<Self>) -> Receiver<SearchResult> {\n        let (result_tx, result_rx) = smol::channel::unbounded();\n\n        let matching_buffers_rx = if query.is_opened_only() {\n            self.sort_search_candidates(&query, cx)\n        } else {\n            self.find_search_candidate_buffers(&query, MAX_SEARCH_RESULT_FILES + 1, cx)\n        };\n\n        cx.spawn(|_, cx| async move {\n            let mut range_count = 0;\n            let mut buffer_count = 0;\n            let mut limit_reached = false;\n            let query = Arc::new(query);\n            let mut chunks = matching_buffers_rx.ready_chunks(64);\n\n            // Now that we know what paths match the query, we will load at most\n            // 64 buffers at a time to avoid overwhelming the main thread. For each\n            // opened buffer, we will spawn a background task that retrieves all the\n            // ranges in the buffer matched by the query.\n            let mut chunks = pin!(chunks);\n            'outer: while let Some(matching_buffer_chunk) = chunks.next().await {\n                let mut chunk_results = Vec::new();\n                for buffer in matching_buffer_chunk {\n                    let buffer = buffer.clone();\n                    let query = query.clone();\n                    let snapshot = buffer.read_with(&cx, |buffer, _| buffer.snapshot())?;\n                    chunk_results.push(cx.background_executor().spawn(async move {\n                        let ranges = query\n                            .search(&snapshot, None)\n                            .await\n                            .iter()\n                            .map(|range| {\n                                snapshot.anchor_before(range.start)\n                                    ..snapshot.anchor_after(range.end)\n                            })\n                            .collect::<Vec<_>>();\n                        anyhow::Ok((buffer, ranges))\n                    }));\n                }\n\n                let chunk_results = futures::future::join_all(chunk_results).await;\n                for result in chunk_results {\n                    if let Some((buffer, ranges)) = result.log_err() {\n                        range_count += ranges.len();\n                        buffer_count += 1;\n                        result_tx\n                            .send(SearchResult::Buffer { buffer, ranges })\n                            .await?;\n                        if buffer_count > MAX_SEARCH_RESULT_FILES\n                            || range_count > MAX_SEARCH_RESULT_RANGES\n                        {\n                            limit_reached = true;\n                            break 'outer;\n                        }\n                    }\n                }\n            }\n\n            if limit_reached {\n                result_tx.send(SearchResult::LimitReached).await?;\n            }\n\n            anyhow::Ok(())\n        })\n        .detach();\n\n        result_rx\n    }\n\n    fn find_search_candidate_buffers(\n        &mut self,\n        query: &SearchQuery,\n        limit: usize,\n        cx: &mut Context<Project>,\n    ) -> Receiver<Entity<Buffer>> {\n        if self.is_local() {\n            let fs = self.fs.clone();\n            self.buffer_store.update(cx, |buffer_store, cx| {\n                buffer_store.find_search_candidates(query, limit, fs, cx)\n            })\n        } else {\n            self.find_search_candidates_remote(query, limit, cx)\n        }\n    }\n\n    fn sort_search_candidates(\n        &mut self,\n        search_query: &SearchQuery,\n        cx: &mut Context<Project>,\n    ) -> Receiver<Entity<Buffer>> {\n        let worktree_store = self.worktree_store.read(cx);\n        let mut buffers = search_query\n            .buffers()\n            .into_iter()\n            .flatten()\n            .filter(|buffer| {\n                let b = buffer.read(cx);\n                if let Some(file) = b.file() {\n                    if !search_query.file_matches(file.path()) {\n                        return false;\n                    }\n                    if let Some(entry) = b\n                        .entry_id(cx)\n                        .and_then(|entry_id| worktree_store.entry_for_id(entry_id, cx))\n                    {\n                        if entry.is_ignored && !search_query.include_ignored() {\n                            return false;\n                        }\n                    }\n                }\n                true\n            })\n            .collect::<Vec<_>>();\n        let (tx, rx) = smol::channel::unbounded();\n        buffers.sort_by(|a, b| match (a.read(cx).file(), b.read(cx).file()) {\n            (None, None) => a.read(cx).remote_id().cmp(&b.read(cx).remote_id()),\n            (None, Some(_)) => std::cmp::Ordering::Less,\n            (Some(_), None) => std::cmp::Ordering::Greater,\n            (Some(a), Some(b)) => compare_paths((a.path(), true), (b.path(), true)),\n        });\n        for buffer in buffers {\n            tx.send_blocking(buffer.clone()).unwrap()\n        }\n\n        rx\n    }\n\n    fn find_search_candidates_remote(\n        &mut self,\n        query: &SearchQuery,\n        limit: usize,\n        cx: &mut Context<Project>,\n    ) -> Receiver<Entity<Buffer>> {\n        let (tx, rx) = smol::channel::unbounded();\n\n        let (client, remote_id): (AnyProtoClient, _) = if let Some(ssh_client) = &self.ssh_client {\n            (ssh_client.read(cx).proto_client(), 0)\n        } else if let Some(remote_id) = self.remote_id() {\n            (self.client.clone().into(), remote_id)\n        } else {\n            return rx;\n        };\n\n        let request = client.request(proto::FindSearchCandidates {\n            project_id: remote_id,\n            query: Some(query.to_proto()),\n            limit: limit as _,\n        });\n        let guard = self.retain_remotely_created_models(cx);\n\n        cx.spawn(move |project, mut cx| async move {\n            let response = request.await?;\n            for buffer_id in response.buffer_ids {\n                let buffer_id = BufferId::new(buffer_id)?;\n                let buffer = project\n                    .update(&mut cx, |project, cx| {\n                        project.buffer_store.update(cx, |buffer_store, cx| {\n                            buffer_store.wait_for_remote_buffer(buffer_id, cx)\n                        })\n                    })?\n                    .await?;\n                let _ = tx.send(buffer).await;\n            }\n\n            drop(guard);\n            anyhow::Ok(())\n        })\n        .detach_and_log_err(cx);\n        rx\n    }\n\n    pub fn request_lsp<R: LspCommand>(\n        &mut self,\n        buffer_handle: Entity<Buffer>,\n        server: LanguageServerToQuery,\n        request: R,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<R::Response>>\n    where\n        <R::LspRequest as lsp::request::Request>::Result: Send,\n        <R::LspRequest as lsp::request::Request>::Params: Send,\n    {\n        let guard = self.retain_remotely_created_models(cx);\n        let task = self.lsp_store.update(cx, |lsp_store, cx| {\n            lsp_store.request_lsp(buffer_handle, server, request, cx)\n        });\n        cx.spawn(|_, _| async move {\n            let result = task.await;\n            drop(guard);\n            result\n        })\n    }\n\n    /// Move a worktree to a new position in the worktree order.\n    ///\n    /// The worktree will moved to the opposite side of the destination worktree.\n    ///\n    /// # Example\n    ///\n    /// Given the worktree order `[11, 22, 33]` and a call to move worktree `22` to `33`,\n    /// worktree_order will be updated to produce the indexes `[11, 33, 22]`.\n    ///\n    /// Given the worktree order `[11, 22, 33]` and a call to move worktree `22` to `11`,\n    /// worktree_order will be updated to produce the indexes `[22, 11, 33]`.\n    ///\n    /// # Errors\n    ///\n    /// An error will be returned if the worktree or destination worktree are not found.\n    pub fn move_worktree(\n        &mut self,\n        source: WorktreeId,\n        destination: WorktreeId,\n        cx: &mut Context<'_, Self>,\n    ) -> Result<()> {\n        self.worktree_store.update(cx, |worktree_store, cx| {\n            worktree_store.move_worktree(source, destination, cx)\n        })\n    }\n\n    pub fn find_or_create_worktree(\n        &mut self,\n        abs_path: impl AsRef<Path>,\n        visible: bool,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<(Entity<Worktree>, PathBuf)>> {\n        self.worktree_store.update(cx, |worktree_store, cx| {\n            worktree_store.find_or_create_worktree(abs_path, visible, cx)\n        })\n    }\n\n    pub fn find_worktree(&self, abs_path: &Path, cx: &App) -> Option<(Entity<Worktree>, PathBuf)> {\n        self.worktree_store.read_with(cx, |worktree_store, cx| {\n            worktree_store.find_worktree(abs_path, cx)\n        })\n    }\n\n    pub fn is_shared(&self) -> bool {\n        match &self.client_state {\n            ProjectClientState::Shared { .. } => true,\n            ProjectClientState::Local => false,\n            ProjectClientState::Remote { .. } => true,\n        }\n    }\n\n    /// Returns the resolved version of `path`, that was found in `buffer`, if it exists.\n    pub fn resolve_path_in_buffer(\n        &self,\n        path: &str,\n        buffer: &Entity<Buffer>,\n        cx: &mut Context<Self>,\n    ) -> Task<Option<ResolvedPath>> {\n        let path_buf = PathBuf::from(path);\n        if path_buf.is_absolute() || path.starts_with(\"~\") {\n            self.resolve_abs_path(path, cx)\n        } else {\n            self.resolve_path_in_worktrees(path_buf, buffer, cx)\n        }\n    }\n\n    pub fn resolve_abs_file_path(\n        &self,\n        path: &str,\n        cx: &mut Context<Self>,\n    ) -> Task<Option<ResolvedPath>> {\n        let resolve_task = self.resolve_abs_path(path, cx);\n        cx.background_executor().spawn(async move {\n            let resolved_path = resolve_task.await;\n            resolved_path.filter(|path| path.is_file())\n        })\n    }\n\n    pub fn resolve_abs_path(\n        &self,\n        path: &str,\n        cx: &mut Context<Self>,\n    ) -> Task<Option<ResolvedPath>> {\n        if self.is_local() {\n            let expanded = PathBuf::from(shellexpand::tilde(&path).into_owned());\n            let fs = self.fs.clone();\n            cx.background_executor().spawn(async move {\n                let path = expanded.as_path();\n                let metadata = fs.metadata(path).await.ok().flatten();\n\n                metadata.map(|metadata| ResolvedPath::AbsPath {\n                    path: expanded,\n                    is_dir: metadata.is_dir,\n                })\n            })\n        } else if let Some(ssh_client) = self.ssh_client.as_ref() {\n            let request_path = Path::new(path);\n            let request = ssh_client\n                .read(cx)\n                .proto_client()\n                .request(proto::GetPathMetadata {\n                    project_id: SSH_PROJECT_ID,\n                    path: request_path.to_proto(),\n                });\n            cx.background_executor().spawn(async move {\n                let response = request.await.log_err()?;\n                if response.exists {\n                    Some(ResolvedPath::AbsPath {\n                        path: PathBuf::from_proto(response.path),\n                        is_dir: response.is_dir,\n                    })\n                } else {\n                    None\n                }\n            })\n        } else {\n            return Task::ready(None);\n        }\n    }\n\n    fn resolve_path_in_worktrees(\n        &self,\n        path: PathBuf,\n        buffer: &Entity<Buffer>,\n        cx: &mut Context<Self>,\n    ) -> Task<Option<ResolvedPath>> {\n        let mut candidates = vec![path.clone()];\n\n        if let Some(file) = buffer.read(cx).file() {\n            if let Some(dir) = file.path().parent() {\n                let joined = dir.to_path_buf().join(path);\n                candidates.push(joined);\n            }\n        }\n\n        let worktrees = self.worktrees(cx).collect::<Vec<_>>();\n        cx.spawn(|_, mut cx| async move {\n            for worktree in worktrees {\n                for candidate in candidates.iter() {\n                    let path = worktree\n                        .update(&mut cx, |worktree, _| {\n                            let root_entry_path = &worktree.root_entry()?.path;\n\n                            let resolved = resolve_path(root_entry_path, candidate);\n\n                            let stripped =\n                                resolved.strip_prefix(root_entry_path).unwrap_or(&resolved);\n\n                            worktree.entry_for_path(stripped).map(|entry| {\n                                let project_path = ProjectPath {\n                                    worktree_id: worktree.id(),\n                                    path: entry.path.clone(),\n                                };\n                                ResolvedPath::ProjectPath {\n                                    project_path,\n                                    is_dir: entry.is_dir(),\n                                }\n                            })\n                        })\n                        .ok()?;\n\n                    if path.is_some() {\n                        return path;\n                    }\n                }\n            }\n            None\n        })\n    }\n\n    pub fn list_directory(\n        &self,\n        query: String,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Vec<PathBuf>>> {\n        if self.is_local() {\n            DirectoryLister::Local(self.fs.clone()).list_directory(query, cx)\n        } else if let Some(session) = self.ssh_client.as_ref() {\n            let path_buf = PathBuf::from(query);\n            let request = proto::ListRemoteDirectory {\n                dev_server_id: SSH_PROJECT_ID,\n                path: path_buf.to_proto(),\n            };\n\n            let response = session.read(cx).proto_client().request(request);\n            cx.background_executor().spawn(async move {\n                let response = response.await?;\n                Ok(response.entries.into_iter().map(PathBuf::from).collect())\n            })\n        } else {\n            Task::ready(Err(anyhow!(\"cannot list directory in remote project\")))\n        }\n    }\n\n    pub fn create_worktree(\n        &mut self,\n        abs_path: impl AsRef<Path>,\n        visible: bool,\n        cx: &mut Context<Self>,\n    ) -> Task<Result<Entity<Worktree>>> {\n        self.worktree_store.update(cx, |worktree_store, cx| {\n            worktree_store.create_worktree(abs_path, visible, cx)\n        })\n    }\n\n    pub fn remove_worktree(&mut self, id_to_remove: WorktreeId, cx: &mut Context<Self>) {\n        self.worktree_store.update(cx, |worktree_store, cx| {\n            worktree_store.remove_worktree(id_to_remove, cx);\n        });\n    }\n\n    fn add_worktree(&mut self, worktree: &Entity<Worktree>, cx: &mut Context<Self>) {\n        self.worktree_store.update(cx, |worktree_store, cx| {\n            worktree_store.add(worktree, cx);\n        });\n    }\n\n    pub fn set_active_path(&mut self, entry: Option<ProjectPath>, cx: &mut Context<Self>) {\n        let new_active_entry = entry.and_then(|project_path| {\n            let worktree = self.worktree_for_id(project_path.worktree_id, cx)?;\n            let entry = worktree.read(cx).entry_for_path(project_path.path)?;\n            Some(entry.id)\n        });\n        if new_active_entry != self.active_entry {\n            self.active_entry = new_active_entry;\n            self.lsp_store.update(cx, |lsp_store, _| {\n                lsp_store.set_active_entry(new_active_entry);\n            });\n            cx.emit(Event::ActiveEntryChanged(new_active_entry));\n        }\n    }\n\n    pub fn language_servers_running_disk_based_diagnostics<'a>(\n        &'a self,\n        cx: &'a App,\n    ) -> impl Iterator<Item = LanguageServerId> + 'a {\n        self.lsp_store\n            .read(cx)\n            .language_servers_running_disk_based_diagnostics()\n    }\n\n    pub fn diagnostic_summary(&self, include_ignored: bool, cx: &App) -> DiagnosticSummary {\n        self.lsp_store\n            .read(cx)\n            .diagnostic_summary(include_ignored, cx)\n    }\n\n    pub fn diagnostic_summaries<'a>(\n        &'a self,\n        include_ignored: bool,\n        cx: &'a App,\n    ) -> impl Iterator<Item = (ProjectPath, LanguageServerId, DiagnosticSummary)> + 'a {\n        self.lsp_store\n            .read(cx)\n            .diagnostic_summaries(include_ignored, cx)\n    }\n\n    pub fn active_entry(&self) -> Option<ProjectEntryId> {\n        self.active_entry\n    }\n\n    pub fn entry_for_path(&self, path: &ProjectPath, cx: &App) -> Option<Entry> {\n        self.worktree_store.read(cx).entry_for_path(path, cx)\n    }\n\n    pub fn path_for_entry(&self, entry_id: ProjectEntryId, cx: &App) -> Option<ProjectPath> {\n        let worktree = self.worktree_for_entry(entry_id, cx)?;\n        let worktree = worktree.read(cx);\n        let worktree_id = worktree.id();\n        let path = worktree.entry_for_id(entry_id)?.path.clone();\n        Some(ProjectPath { worktree_id, path })\n    }\n\n    pub fn absolute_path(&self, project_path: &ProjectPath, cx: &App) -> Option<PathBuf> {\n        self.worktree_for_id(project_path.worktree_id, cx)?\n            .read(cx)\n            .absolutize(&project_path.path)\n            .ok()\n    }\n\n    /// Attempts to find a `ProjectPath` corresponding to the given path. If the path\n    /// is a *full path*, meaning it starts with the root name of a worktree, we'll locate\n    /// it in that worktree. Otherwise, we'll attempt to find it as a relative path in\n    /// the first visible worktree that has an entry for that relative path.\n    ///\n    /// We use this to resolve edit steps, when there's a chance an LLM may omit the workree\n    /// root name from paths.\n    ///\n    /// # Arguments\n    ///\n    /// * `path` - A full path that starts with a worktree root name, or alternatively a\n    ///            relative path within a visible worktree.\n    /// * `cx` - A reference to the `AppContext`.\n    ///\n    /// # Returns\n    ///\n    /// Returns `Some(ProjectPath)` if a matching worktree is found, otherwise `None`.\n    pub fn find_project_path(&self, path: &Path, cx: &App) -> Option<ProjectPath> {\n        let worktree_store = self.worktree_store.read(cx);\n\n        for worktree in worktree_store.visible_worktrees(cx) {\n            let worktree_root_name = worktree.read(cx).root_name();\n            if let Ok(relative_path) = path.strip_prefix(worktree_root_name) {\n                return Some(ProjectPath {\n                    worktree_id: worktree.read(cx).id(),\n                    path: relative_path.into(),\n                });\n            }\n        }\n\n        for worktree in worktree_store.visible_worktrees(cx) {\n            let worktree = worktree.read(cx);\n            if let Some(entry) = worktree.entry_for_path(path) {\n                return Some(ProjectPath {\n                    worktree_id: worktree.id(),\n                    path: entry.path.clone(),\n                });\n            }\n        }\n\n        None\n    }\n\n    pub fn get_workspace_root(&self, project_path: &ProjectPath, cx: &App) -> Option<PathBuf> {\n        Some(\n            self.worktree_for_id(project_path.worktree_id, cx)?\n                .read(cx)\n                .abs_path()\n                .to_path_buf(),\n        )\n    }\n\n    pub fn get_first_worktree_root_repo(&self, cx: &App) -> Option<Arc<dyn GitRepository>> {\n        let worktree = self.visible_worktrees(cx).next()?.read(cx).as_local()?;\n        let root_entry = worktree.root_git_entry()?;\n        worktree.get_local_repo(&root_entry)?.repo().clone().into()\n    }\n\n    pub fn branches(&self, project_path: ProjectPath, cx: &App) -> Task<Result<Vec<Branch>>> {\n        self.worktree_store().read(cx).branches(project_path, cx)\n    }\n\n    pub fn update_or_create_branch(\n        &self,\n        repository: ProjectPath,\n        new_branch: String,\n        cx: &App,\n    ) -> Task<Result<()>> {\n        self.worktree_store()\n            .read(cx)\n            .update_or_create_branch(repository, new_branch, cx)\n    }\n\n    pub fn blame_buffer(\n        &self,\n        buffer: &Entity<Buffer>,\n        version: Option<clock::Global>,\n        cx: &App,\n    ) -> Task<Result<Option<Blame>>> {\n        self.buffer_store.read(cx).blame_buffer(buffer, version, cx)\n    }\n\n    pub fn get_permalink_to_line(\n        &self,\n        buffer: &Entity<Buffer>,\n        selection: Range<u32>,\n        cx: &App,\n    ) -> Task<Result<url::Url>> {\n        self.buffer_store\n            .read(cx)\n            .get_permalink_to_line(buffer, selection, cx)\n    }\n\n    // RPC message handlers\n\n    async fn handle_unshare_project(\n        this: Entity<Self>,\n        _: TypedEnvelope<proto::UnshareProject>,\n        mut cx: AsyncApp,\n    ) -> Result<()> {\n        this.update(&mut cx, |this, cx| {\n            if this.is_local() || this.is_via_ssh() {\n                this.unshare(cx)?;\n            } else {\n                this.disconnected_from_host(cx);\n            }\n            Ok(())\n        })?\n    }\n\n    async fn handle_add_collaborator(\n        this: Entity<Self>,\n        mut envelope: TypedEnvelope<proto::AddProjectCollaborator>,\n        mut cx: AsyncApp,\n    ) -> Result<()> {\n        let collaborator = envelope\n            .payload\n            .collaborator\n            .take()\n            .ok_or_else(|| anyhow!(\"empty collaborator\"))?;\n\n        let collaborator = Collaborator::from_proto(collaborator)?;\n        this.update(&mut cx, |this, cx| {\n            this.buffer_store.update(cx, |buffer_store, _| {\n                buffer_store.forget_shared_buffers_for(&collaborator.peer_id);\n            });\n            cx.emit(Event::CollaboratorJoined(collaborator.peer_id));\n            this.collaborators\n                .insert(collaborator.peer_id, collaborator);\n            cx.notify();\n        })?;\n\n        Ok(())\n    }\n\n    async fn handle_update_project_collaborator(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::UpdateProjectCollaborator>,\n        mut cx: AsyncApp,\n    ) -> Result<()> {\n        let old_peer_id = envelope\n            .payload\n            .old_peer_id\n            .ok_or_else(|| anyhow!(\"missing old peer id\"))?;\n        let new_peer_id = envelope\n            .payload\n            .new_peer_id\n            .ok_or_else(|| anyhow!(\"missing new peer id\"))?;\n        this.update(&mut cx, |this, cx| {\n            let collaborator = this\n                .collaborators\n                .remove(&old_peer_id)\n                .ok_or_else(|| anyhow!(\"received UpdateProjectCollaborator for unknown peer\"))?;\n            let is_host = collaborator.is_host;\n            this.collaborators.insert(new_peer_id, collaborator);\n\n            log::info!(\"peer {} became {}\", old_peer_id, new_peer_id,);\n            this.buffer_store.update(cx, |buffer_store, _| {\n                buffer_store.update_peer_id(&old_peer_id, new_peer_id)\n            });\n\n            if is_host {\n                this.buffer_store\n                    .update(cx, |buffer_store, _| buffer_store.discard_incomplete());\n                this.enqueue_buffer_ordered_message(BufferOrderedMessage::Resync)\n                    .unwrap();\n                cx.emit(Event::HostReshared);\n            }\n\n            cx.emit(Event::CollaboratorUpdated {\n                old_peer_id,\n                new_peer_id,\n            });\n            cx.notify();\n            Ok(())\n        })?\n    }\n\n    async fn handle_remove_collaborator(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::RemoveProjectCollaborator>,\n        mut cx: AsyncApp,\n    ) -> Result<()> {\n        this.update(&mut cx, |this, cx| {\n            let peer_id = envelope\n                .payload\n                .peer_id\n                .ok_or_else(|| anyhow!(\"invalid peer id\"))?;\n            let replica_id = this\n                .collaborators\n                .remove(&peer_id)\n                .ok_or_else(|| anyhow!(\"unknown peer {:?}\", peer_id))?\n                .replica_id;\n            this.buffer_store.update(cx, |buffer_store, cx| {\n                buffer_store.forget_shared_buffers_for(&peer_id);\n                for buffer in buffer_store.buffers() {\n                    buffer.update(cx, |buffer, cx| buffer.remove_peer(replica_id, cx));\n                }\n            });\n\n            cx.emit(Event::CollaboratorLeft(peer_id));\n            cx.notify();\n            Ok(())\n        })?\n    }\n\n    async fn handle_update_project(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::UpdateProject>,\n        mut cx: AsyncApp,\n    ) -> Result<()> {\n        this.update(&mut cx, |this, cx| {\n            // Don't handle messages that were sent before the response to us joining the project\n            if envelope.message_id > this.join_project_response_message_id {\n                this.set_worktrees_from_proto(envelope.payload.worktrees, cx)?;\n            }\n            Ok(())\n        })?\n    }\n\n    async fn handle_toast(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::Toast>,\n        mut cx: AsyncApp,\n    ) -> Result<()> {\n        this.update(&mut cx, |_, cx| {\n            cx.emit(Event::Toast {\n                notification_id: envelope.payload.notification_id.into(),\n                message: envelope.payload.message,\n            });\n            Ok(())\n        })?\n    }\n\n    async fn handle_language_server_prompt_request(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::LanguageServerPromptRequest>,\n        mut cx: AsyncApp,\n    ) -> Result<proto::LanguageServerPromptResponse> {\n        let (tx, mut rx) = smol::channel::bounded(1);\n        let actions: Vec<_> = envelope\n            .payload\n            .actions\n            .into_iter()\n            .map(|action| MessageActionItem {\n                title: action,\n                properties: Default::default(),\n            })\n            .collect();\n        this.update(&mut cx, |_, cx| {\n            cx.emit(Event::LanguageServerPrompt(LanguageServerPromptRequest {\n                level: proto_to_prompt(envelope.payload.level.context(\"Invalid prompt level\")?),\n                message: envelope.payload.message,\n                actions: actions.clone(),\n                lsp_name: envelope.payload.lsp_name,\n                response_channel: tx,\n            }));\n\n            anyhow::Ok(())\n        })??;\n\n        // We drop `this` to avoid holding a reference in this future for too\n        // long.\n        // If we keep the reference, we might not drop the `Project` early\n        // enough when closing a window and it will only get releases on the\n        // next `flush_effects()` call.\n        drop(this);\n\n        let mut rx = pin!(rx);\n        let answer = rx.next().await;\n\n        Ok(LanguageServerPromptResponse {\n            action_response: answer.and_then(|answer| {\n                actions\n                    .iter()\n                    .position(|action| *action == answer)\n                    .map(|index| index as u64)\n            }),\n        })\n    }\n\n    async fn handle_hide_toast(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::HideToast>,\n        mut cx: AsyncApp,\n    ) -> Result<()> {\n        this.update(&mut cx, |_, cx| {\n            cx.emit(Event::HideToast {\n                notification_id: envelope.payload.notification_id.into(),\n            });\n            Ok(())\n        })?\n    }\n\n    // Collab sends UpdateWorktree protos as messages\n    async fn handle_update_worktree(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::UpdateWorktree>,\n        mut cx: AsyncApp,\n    ) -> Result<()> {\n        this.update(&mut cx, |this, cx| {\n            let worktree_id = WorktreeId::from_proto(envelope.payload.worktree_id);\n            if let Some(worktree) = this.worktree_for_id(worktree_id, cx) {\n                worktree.update(cx, |worktree, _| {\n                    let worktree = worktree.as_remote_mut().unwrap();\n                    worktree.update_from_remote(envelope.payload);\n                });\n            }\n            Ok(())\n        })?\n    }\n\n    async fn handle_update_buffer_from_ssh(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::UpdateBuffer>,\n        cx: AsyncApp,\n    ) -> Result<proto::Ack> {\n        let buffer_store = this.read_with(&cx, |this, cx| {\n            if let Some(remote_id) = this.remote_id() {\n                let mut payload = envelope.payload.clone();\n                payload.project_id = remote_id;\n                cx.background_executor()\n                    .spawn(this.client.request(payload))\n                    .detach_and_log_err(cx);\n            }\n            this.buffer_store.clone()\n        })?;\n        BufferStore::handle_update_buffer(buffer_store, envelope, cx).await\n    }\n\n    async fn handle_update_buffer(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::UpdateBuffer>,\n        cx: AsyncApp,\n    ) -> Result<proto::Ack> {\n        let buffer_store = this.read_with(&cx, |this, cx| {\n            if let Some(ssh) = &this.ssh_client {\n                let mut payload = envelope.payload.clone();\n                payload.project_id = SSH_PROJECT_ID;\n                cx.background_executor()\n                    .spawn(ssh.read(cx).proto_client().request(payload))\n                    .detach_and_log_err(cx);\n            }\n            this.buffer_store.clone()\n        })?;\n        BufferStore::handle_update_buffer(buffer_store, envelope, cx).await\n    }\n\n    fn retain_remotely_created_models(\n        &mut self,\n        cx: &mut Context<Self>,\n    ) -> RemotelyCreatedModelGuard {\n        {\n            let mut remotely_create_models = self.remotely_created_models.lock();\n            if remotely_create_models.retain_count == 0 {\n                remotely_create_models.buffers = self.buffer_store.read(cx).buffers().collect();\n                remotely_create_models.worktrees =\n                    self.worktree_store.read(cx).worktrees().collect();\n            }\n            remotely_create_models.retain_count += 1;\n        }\n        RemotelyCreatedModelGuard {\n            remote_models: Arc::downgrade(&self.remotely_created_models),\n        }\n    }\n\n    async fn handle_create_buffer_for_peer(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::CreateBufferForPeer>,\n        mut cx: AsyncApp,\n    ) -> Result<()> {\n        this.update(&mut cx, |this, cx| {\n            this.buffer_store.update(cx, |buffer_store, cx| {\n                buffer_store.handle_create_buffer_for_peer(\n                    envelope,\n                    this.replica_id(),\n                    this.capability(),\n                    cx,\n                )\n            })\n        })?\n    }\n\n    async fn handle_synchronize_buffers(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::SynchronizeBuffers>,\n        mut cx: AsyncApp,\n    ) -> Result<proto::SynchronizeBuffersResponse> {\n        let response = this.update(&mut cx, |this, cx| {\n            let client = this.client.clone();\n            this.buffer_store.update(cx, |this, cx| {\n                this.handle_synchronize_buffers(envelope, cx, client)\n            })\n        })??;\n\n        Ok(response)\n    }\n\n    async fn handle_search_candidate_buffers(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::FindSearchCandidates>,\n        mut cx: AsyncApp,\n    ) -> Result<proto::FindSearchCandidatesResponse> {\n        let peer_id = envelope.original_sender_id()?;\n        let message = envelope.payload;\n        let query = SearchQuery::from_proto(\n            message\n                .query\n                .ok_or_else(|| anyhow!(\"missing query field\"))?,\n        )?;\n        let results = this.update(&mut cx, |this, cx| {\n            this.find_search_candidate_buffers(&query, message.limit as _, cx)\n        })?;\n\n        let mut response = proto::FindSearchCandidatesResponse {\n            buffer_ids: Vec::new(),\n        };\n\n        while let Ok(buffer) = results.recv().await {\n            this.update(&mut cx, |this, cx| {\n                let buffer_id = this.create_buffer_for_peer(&buffer, peer_id, cx);\n                response.buffer_ids.push(buffer_id.to_proto());\n            })?;\n        }\n\n        Ok(response)\n    }\n\n    async fn handle_open_buffer_by_id(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::OpenBufferById>,\n        mut cx: AsyncApp,\n    ) -> Result<proto::OpenBufferResponse> {\n        let peer_id = envelope.original_sender_id()?;\n        let buffer_id = BufferId::new(envelope.payload.id)?;\n        let buffer = this\n            .update(&mut cx, |this, cx| this.open_buffer_by_id(buffer_id, cx))?\n            .await?;\n        Project::respond_to_open_buffer_request(this, buffer, peer_id, &mut cx)\n    }\n\n    async fn handle_open_buffer_by_path(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::OpenBufferByPath>,\n        mut cx: AsyncApp,\n    ) -> Result<proto::OpenBufferResponse> {\n        let peer_id = envelope.original_sender_id()?;\n        let worktree_id = WorktreeId::from_proto(envelope.payload.worktree_id);\n        let open_buffer = this.update(&mut cx, |this, cx| {\n            this.open_buffer(\n                ProjectPath {\n                    worktree_id,\n                    path: Arc::<Path>::from_proto(envelope.payload.path),\n                },\n                cx,\n            )\n        })?;\n\n        let buffer = open_buffer.await?;\n        Project::respond_to_open_buffer_request(this, buffer, peer_id, &mut cx)\n    }\n\n    async fn handle_open_new_buffer(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::OpenNewBuffer>,\n        mut cx: AsyncApp,\n    ) -> Result<proto::OpenBufferResponse> {\n        let buffer = this\n            .update(&mut cx, |this, cx| this.create_buffer(cx))?\n            .await?;\n        let peer_id = envelope.original_sender_id()?;\n\n        Project::respond_to_open_buffer_request(this, buffer, peer_id, &mut cx)\n    }\n\n    async fn handle_stage(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::Stage>,\n        mut cx: AsyncApp,\n    ) -> Result<proto::Ack> {\n        let worktree_id = WorktreeId::from_proto(envelope.payload.worktree_id);\n        let work_directory_id = ProjectEntryId::from_proto(envelope.payload.work_directory_id);\n        let repository_handle =\n            Self::repository_for_request(&this, worktree_id, work_directory_id, &mut cx)?;\n\n        let entries = envelope\n            .payload\n            .paths\n            .into_iter()\n            .map(PathBuf::from)\n            .map(RepoPath::new)\n            .collect();\n\n        repository_handle\n            .update(&mut cx, |repository_handle, _| {\n                repository_handle.stage_entries(entries)\n            })?\n            .await??;\n        Ok(proto::Ack {})\n    }\n\n    async fn handle_unstage(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::Unstage>,\n        mut cx: AsyncApp,\n    ) -> Result<proto::Ack> {\n        let worktree_id = WorktreeId::from_proto(envelope.payload.worktree_id);\n        let work_directory_id = ProjectEntryId::from_proto(envelope.payload.work_directory_id);\n        let repository_handle =\n            Self::repository_for_request(&this, worktree_id, work_directory_id, &mut cx)?;\n\n        let entries = envelope\n            .payload\n            .paths\n            .into_iter()\n            .map(PathBuf::from)\n            .map(RepoPath::new)\n            .collect();\n\n        repository_handle\n            .update(&mut cx, |repository_handle, _| {\n                repository_handle.unstage_entries(entries)\n            })?\n            .await??;\n        Ok(proto::Ack {})\n    }\n\n    async fn handle_commit(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::Commit>,\n        mut cx: AsyncApp,\n    ) -> Result<proto::Ack> {\n        let worktree_id = WorktreeId::from_proto(envelope.payload.worktree_id);\n        let work_directory_id = ProjectEntryId::from_proto(envelope.payload.work_directory_id);\n        let repository_handle =\n            Self::repository_for_request(&this, worktree_id, work_directory_id, &mut cx)?;\n\n        let message = SharedString::from(envelope.payload.message);\n        let name = envelope.payload.name.map(SharedString::from);\n        let email = envelope.payload.email.map(SharedString::from);\n        repository_handle\n            .update(&mut cx, |repository_handle, _| {\n                repository_handle.commit(message, name.zip(email))\n            })?\n            .await??;\n        Ok(proto::Ack {})\n    }\n\n    async fn handle_open_commit_message_buffer(\n        this: Entity<Self>,\n        envelope: TypedEnvelope<proto::OpenCommitMessageBuffer>,\n        mut cx: AsyncApp,\n    ) -> Result<proto::OpenBufferResponse> {\n        let worktree_id = WorktreeId::from_proto(envelope.payload.worktree_id);\n        let work_directory_id = ProjectEntryId::from_proto(envelope.payload.work_directory_id);\n        let repository_handle =\n            Self::repository_for_request(&this, worktree_id, work_directory_id, &mut cx)?;\n        let buffer = repository_handle\n            .update(&mut cx, |repository_handle, cx| {\n                repository_handle.open_commit_buffer(None, this.read(cx).buffer_store.clone(), cx)\n            })?\n            .await?;\n\n        let peer_id = envelope.original_sender_id()?;\n        Project::respond_to_open_buffer_request(this, buffer, peer_id, &mut cx)\n    }\n\n    fn repository_for_request(\n        this: &Entity<Self>,\n        worktree_id: WorktreeId,\n        work_directory_id: ProjectEntryId,\n        cx: &mut AsyncApp,\n    ) -> Result<Entity<Repository>> {\n        this.update(cx, |project, cx| {\n            let repository_handle = project\n                .git_state()\n                .read(cx)\n                .all_repositories()\n                .into_iter()\n                .find(|repository_handle| {\n                    let repository_handle = repository_handle.read(cx);\n                    repository_handle.worktree_id == worktree_id\n                        && repository_handle.repository_entry.work_directory_id()\n                            == work_directory_id\n                })\n                .context(\"missing repository handle\")?;\n            anyhow::Ok(repository_handle)\n        })?\n    }\n\n    fn respond_to_open_buffer_request(\n        this: Entity<Self>,\n        buffer: Entity<Buffer>,\n        peer_id: proto::PeerId,\n        cx: &mut AsyncApp,\n    ) -> Result<proto::OpenBufferResponse> {\n        this.update(cx, |this, cx| {\n            let is_private = buffer\n                .read(cx)\n                .file()\n                .map(|f| f.is_private())\n                .unwrap_or_default();\n            if is_private {\n                Err(anyhow!(ErrorCode::UnsharedItem))\n            } else {\n                Ok(proto::OpenBufferResponse {\n                    buffer_id: this.create_buffer_for_peer(&buffer, peer_id, cx).into(),\n                })\n            }\n        })?\n    }\n\n    fn create_buffer_for_peer(\n        &mut self,\n        buffer: &Entity<Buffer>,\n        peer_id: proto::PeerId,\n        cx: &mut App,\n    ) -> BufferId {\n        self.buffer_store\n            .update(cx, |buffer_store, cx| {\n                buffer_store.create_buffer_for_peer(buffer, peer_id, cx)\n            })\n            .detach_and_log_err(cx);\n        buffer.read(cx).remote_id()\n    }\n\n    fn synchronize_remote_buffers(&mut self, cx: &mut Context<Self>) -> Task<Result<()>> {\n        let project_id = match self.client_state {\n            ProjectClientState::Remote {\n                sharing_has_stopped,\n                remote_id,\n                ..\n            } => {\n                if sharing_has_stopped {\n                    return Task::ready(Err(anyhow!(\n                        \"can't synchronize remote buffers on a readonly project\"\n                    )));\n                } else {\n                    remote_id\n                }\n            }\n            ProjectClientState::Shared { .. } | ProjectClientState::Local => {\n                return Task::ready(Err(anyhow!(\n                    \"can't synchronize remote buffers on a local project\"\n                )))\n            }\n        };\n\n        let client = self.client.clone();\n        cx.spawn(move |this, mut cx| async move {\n            let (buffers, incomplete_buffer_ids) = this.update(&mut cx, |this, cx| {\n                this.buffer_store.read(cx).buffer_version_info(cx)\n            })?;\n            let response = client\n                .request(proto::SynchronizeBuffers {\n                    project_id,\n                    buffers,\n                })\n                .await?;\n\n            let send_updates_for_buffers = this.update(&mut cx, |this, cx| {\n                response\n                    .buffers\n                    .into_iter()\n                    .map(|buffer| {\n                        let client = client.clone();\n                        let buffer_id = match BufferId::new(buffer.id) {\n                            Ok(id) => id,\n                            Err(e) => {\n                                return Task::ready(Err(e));\n                            }\n                        };\n                        let remote_version = language::proto::deserialize_version(&buffer.version);\n                        if let Some(buffer) = this.buffer_for_id(buffer_id, cx) {\n                            let operations =\n                                buffer.read(cx).serialize_ops(Some(remote_version), cx);\n                            cx.background_executor().spawn(async move {\n                                let operations = operations.await;\n                                for chunk in split_operations(operations) {\n                                    client\n                                        .request(proto::UpdateBuffer {\n                                            project_id,\n                                            buffer_id: buffer_id.into(),\n                                            operations: chunk,\n                                        })\n                                        .await?;\n                                }\n                                anyhow::Ok(())\n                            })\n                        } else {\n                            Task::ready(Ok(()))\n                        }\n                    })\n                    .collect::<Vec<_>>()\n            })?;\n\n            // Any incomplete buffers have open requests waiting. Request that the host sends\n            // creates these buffers for us again to unblock any waiting futures.\n            for id in incomplete_buffer_ids {\n                cx.background_executor()\n                    .spawn(client.request(proto::OpenBufferById {\n                        project_id,\n                        id: id.into(),\n                    }))\n                    .detach();\n            }\n\n            futures::future::join_all(send_updates_for_buffers)\n                .await\n                .into_iter()\n                .collect()\n        })\n    }\n\n    pub fn worktree_metadata_protos(&self, cx: &App) -> Vec<proto::WorktreeMetadata> {\n        self.worktree_store.read(cx).worktree_metadata_protos(cx)\n    }\n\n    /// Iterator of all open buffers that have unsaved changes\n    pub fn dirty_buffers<'a>(&'a self, cx: &'a App) -> impl Iterator<Item = ProjectPath> + 'a {\n        self.buffer_store.read(cx).buffers().filter_map(|buf| {\n            let buf = buf.read(cx);\n            if buf.is_dirty() {\n                buf.project_path(cx)\n            } else {\n                None\n            }\n        })\n    }\n\n    fn set_worktrees_from_proto(\n        &mut self,\n        worktrees: Vec<proto::WorktreeMetadata>,\n        cx: &mut Context<Project>,\n    ) -> Result<()> {\n        cx.notify();\n        self.worktree_store.update(cx, |worktree_store, cx| {\n            worktree_store.set_worktrees_from_proto(worktrees, self.replica_id(), cx)\n        })\n    }\n\n    fn set_collaborators_from_proto(\n        &mut self,\n        messages: Vec<proto::Collaborator>,\n        cx: &mut Context<Self>,\n    ) -> Result<()> {\n        let mut collaborators = HashMap::default();\n        for message in messages {\n            let collaborator = Collaborator::from_proto(message)?;\n            collaborators.insert(collaborator.peer_id, collaborator);\n        }\n        for old_peer_id in self.collaborators.keys() {\n            if !collaborators.contains_key(old_peer_id) {\n                cx.emit(Event::CollaboratorLeft(*old_peer_id));\n            }\n        }\n        self.collaborators = collaborators;\n        Ok(())\n    }\n\n    pub fn supplementary_language_servers<'a>(\n        &'a self,\n        cx: &'a App,\n    ) -> impl 'a + Iterator<Item = (LanguageServerId, LanguageServerName)> {\n        self.lsp_store.read(cx).supplementary_language_servers()\n    }\n\n    pub fn language_servers_for_local_buffer<'a>(\n        &'a self,\n        buffer: &'a Buffer,\n        cx: &'a App,\n    ) -> impl Iterator<Item = (&'a Arc<CachedLspAdapter>, &'a Arc<LanguageServer>)> {\n        self.lsp_store\n            .read(cx)\n            .language_servers_for_local_buffer(buffer, cx)\n    }\n\n    pub fn buffer_store(&self) -> &Entity<BufferStore> {\n        &self.buffer_store\n    }\n\n    pub fn git_state(&self) -> &Entity<GitState> {\n        &self.git_state\n    }\n\n    pub fn active_repository(&self, cx: &App) -> Option<Entity<Repository>> {\n        self.git_state.read(cx).active_repository()\n    }\n\n    pub fn all_repositories(&self, cx: &App) -> Vec<Entity<Repository>> {\n        self.git_state.read(cx).all_repositories()\n    }\n}\n\nfn deserialize_code_actions(code_actions: &HashMap<String, bool>) -> Vec<lsp::CodeActionKind> {\n    code_actions\n        .iter()\n        .flat_map(|(kind, enabled)| {\n            if *enabled {\n                Some(kind.clone().into())\n            } else {\n                None\n            }\n        })\n        .collect()\n}\n\npub struct PathMatchCandidateSet {\n    pub snapshot: Snapshot,\n    pub include_ignored: bool,\n    pub include_root_name: bool,\n    pub candidates: Candidates,\n}\n\npub enum Candidates {\n    /// Only consider directories.\n    Directories,\n    /// Only consider files.\n    Files,\n    /// Consider directories and files.\n    Entries,\n}\n\nimpl<'a> fuzzy::PathMatchCandidateSet<'a> for PathMatchCandidateSet {\n    type Candidates = PathMatchCandidateSetIter<'a>;\n\n    fn id(&self) -> usize {\n        self.snapshot.id().to_usize()\n    }\n\n    fn len(&self) -> usize {\n        match self.candidates {\n            Candidates::Files => {\n                if self.include_ignored {\n                    self.snapshot.file_count()\n                } else {\n                    self.snapshot.visible_file_count()\n                }\n            }\n\n            Candidates::Directories => {\n                if self.include_ignored {\n                    self.snapshot.dir_count()\n                } else {\n                    self.snapshot.visible_dir_count()\n                }\n            }\n\n            Candidates::Entries => {\n                if self.include_ignored {\n                    self.snapshot.entry_count()\n                } else {\n                    self.snapshot.visible_entry_count()\n                }\n            }\n        }\n    }\n\n    fn prefix(&self) -> Arc<str> {\n        if self.snapshot.root_entry().map_or(false, |e| e.is_file()) {\n            self.snapshot.root_name().into()\n        } else if self.include_root_name {\n            format!(\"{}{}\", self.snapshot.root_name(), std::path::MAIN_SEPARATOR).into()\n        } else {\n            Arc::default()\n        }\n    }\n\n    fn candidates(&'a self, start: usize) -> Self::Candidates {\n        PathMatchCandidateSetIter {\n            traversal: match self.candidates {\n                Candidates::Directories => self.snapshot.directories(self.include_ignored, start),\n                Candidates::Files => self.snapshot.files(self.include_ignored, start),\n                Candidates::Entries => self.snapshot.entries(self.include_ignored, start),\n            },\n        }\n    }\n}\n\npub struct PathMatchCandidateSetIter<'a> {\n    traversal: Traversal<'a>,\n}\n\nimpl<'a> Iterator for PathMatchCandidateSetIter<'a> {\n    type Item = fuzzy::PathMatchCandidate<'a>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        self.traversal\n            .next()\n            .map(|entry| fuzzy::PathMatchCandidate {\n                is_dir: entry.kind.is_dir(),\n                path: &entry.path,\n                char_bag: entry.char_bag,\n            })\n    }\n}\n\nimpl EventEmitter<Event> for Project {}\n\nimpl<'a> From<&'a ProjectPath> for SettingsLocation<'a> {\n    fn from(val: &'a ProjectPath) -> Self {\n        SettingsLocation {\n            worktree_id: val.worktree_id,\n            path: val.path.as_ref(),\n        }\n    }\n}\n\nimpl<P: AsRef<Path>> From<(WorktreeId, P)> for ProjectPath {\n    fn from((worktree_id, path): (WorktreeId, P)) -> Self {\n        Self {\n            worktree_id,\n            path: path.as_ref().into(),\n        }\n    }\n}\n\npub fn relativize_path(base: &Path, path: &Path) -> PathBuf {\n    let mut path_components = path.components();\n    let mut base_components = base.components();\n    let mut components: Vec<Component> = Vec::new();\n    loop {\n        match (path_components.next(), base_components.next()) {\n            (None, None) => break,\n            (Some(a), None) => {\n                components.push(a);\n                components.extend(path_components.by_ref());\n                break;\n            }\n            (None, _) => components.push(Component::ParentDir),\n            (Some(a), Some(b)) if components.is_empty() && a == b => (),\n            (Some(a), Some(Component::CurDir)) => components.push(a),\n            (Some(a), Some(_)) => {\n                components.push(Component::ParentDir);\n                for _ in base_components {\n                    components.push(Component::ParentDir);\n                }\n                components.push(a);\n                components.extend(path_components.by_ref());\n                break;\n            }\n        }\n    }\n    components.iter().map(|c| c.as_os_str()).collect()\n}\n\nfn resolve_path(base: &Path, path: &Path) -> PathBuf {\n    let mut result = base.to_path_buf();\n    for component in path.components() {\n        match component {\n            Component::ParentDir => {\n                result.pop();\n            }\n            Component::CurDir => (),\n            _ => result.push(component),\n        }\n    }\n    result\n}\n\n/// ResolvedPath is a path that has been resolved to either a ProjectPath\n/// or an AbsPath and that *exists*.\n#[derive(Debug, Clone)]\npub enum ResolvedPath {\n    ProjectPath {\n        project_path: ProjectPath,\n        is_dir: bool,\n    },\n    AbsPath {\n        path: PathBuf,\n        is_dir: bool,\n    },\n}\n\nimpl ResolvedPath {\n    pub fn abs_path(&self) -> Option<&Path> {\n        match self {\n            Self::AbsPath { path, .. } => Some(path.as_path()),\n            _ => None,\n        }\n    }\n\n    pub fn project_path(&self) -> Option<&ProjectPath> {\n        match self {\n            Self::ProjectPath { project_path, .. } => Some(&project_path),\n            _ => None,\n        }\n    }\n\n    pub fn is_file(&self) -> bool {\n        !self.is_dir()\n    }\n\n    pub fn is_dir(&self) -> bool {\n        match self {\n            Self::ProjectPath { is_dir, .. } => *is_dir,\n            Self::AbsPath { is_dir, .. } => *is_dir,\n        }\n    }\n}\n\nimpl ProjectItem for Buffer {\n    fn try_open(\n        project: &Entity<Project>,\n        path: &ProjectPath,\n        cx: &mut App,\n    ) -> Option<Task<Result<Entity<Self>>>> {\n        Some(project.update(cx, |project, cx| project.open_buffer(path.clone(), cx)))\n    }\n\n    fn entry_id(&self, cx: &App) -> Option<ProjectEntryId> {\n        File::from_dyn(self.file()).and_then(|file| file.project_entry_id(cx))\n    }\n\n    fn project_path(&self, cx: &App) -> Option<ProjectPath> {\n        File::from_dyn(self.file()).map(|file| ProjectPath {\n            worktree_id: file.worktree_id(cx),\n            path: file.path().clone(),\n        })\n    }\n\n    fn is_dirty(&self) -> bool {\n        self.is_dirty()\n    }\n}\n\nimpl Completion {\n    /// A key that can be used to sort completions when displaying\n    /// them to the user.\n    pub fn sort_key(&self) -> (usize, &str) {\n        let kind_key = match self.lsp_completion.kind {\n            Some(lsp::CompletionItemKind::KEYWORD) => 0,\n            Some(lsp::CompletionItemKind::VARIABLE) => 1,\n            _ => 2,\n        };\n        (kind_key, &self.label.text[self.label.filter_range.clone()])\n    }\n\n    /// Whether this completion is a snippet.\n    pub fn is_snippet(&self) -> bool {\n        self.lsp_completion.insert_text_format == Some(lsp::InsertTextFormat::SNIPPET)\n    }\n\n    /// Returns the corresponding color for this completion.\n    ///\n    /// Will return `None` if this completion's kind is not [`CompletionItemKind::COLOR`].\n    pub fn color(&self) -> Option<Hsla> {\n        match self.lsp_completion.kind {\n            Some(CompletionItemKind::COLOR) => color_extractor::extract_color(&self.lsp_completion),\n            _ => None,\n        }\n    }\n}\n\npub fn sort_worktree_entries(entries: &mut [impl AsRef<Entry>]) {\n    entries.sort_by(|entry_a, entry_b| {\n        let entry_a = entry_a.as_ref();\n        let entry_b = entry_b.as_ref();\n        compare_paths(\n            (&entry_a.path, entry_a.is_file()),\n            (&entry_b.path, entry_b.is_file()),\n        )\n    });\n}\n\nfn proto_to_prompt(level: proto::language_server_prompt_request::Level) -> gpui::PromptLevel {\n    match level {\n        proto::language_server_prompt_request::Level::Info(_) => gpui::PromptLevel::Info,\n        proto::language_server_prompt_request::Level::Warning(_) => gpui::PromptLevel::Warning,\n        proto::language_server_prompt_request::Level::Critical(_) => gpui::PromptLevel::Critical,\n    }\n}\n```\n\n\nHow can I instantiate a project?\nBased on the code, there are several ways to instantiate a Project depending on your needs:\n\n1. For a Local Project (most common use case):\n\n```rust\nlet project = Project::local(\n    client: Arc<Client>,\n    node: NodeRuntime,\n    user_store: Entity<UserStore>,\n    languages: Arc<LanguageRegistry>,\n    fs: Arc<dyn Fs>,\n    env: Option<HashMap<String, String>>,\n    cx: &mut App,\n) -> Entity<Project>\n```\n\n2. For Testing:\n\n```rust\n// Method 1: Using example()\nlet project = Project::example(\n    root_paths: impl IntoIterator<Item = &Path>,\n    cx: &mut AsyncApp\n).await;\n\n// Method 2: Using test()\nlet project = Project::test(\n    fs: Arc<dyn Fs>,\n    root_paths: impl IntoIterator<Item = &Path>,\n    cx: &mut gpui::TestAppContext\n).await;\n```\n\n3. For Remote Projects:\n\n```rust\nlet project = Project::remote(\n    remote_id: u64,\n    client: Arc<Client>,\n    user_store: Entity<UserStore>,\n    languages: Arc<LanguageRegistry>,\n    fs: Arc<dyn Fs>,\n    cx: AsyncApp\n).await;\n```\n\n4. For SSH Projects:\n\n```rust\nlet project = Project::ssh(\n    ssh: Entity<SshRemoteClient>,\n    client: Arc<Client>,\n    node: NodeRuntime,\n    user_store: Entity<UserStore>,\n    languages: Arc<LanguageRegistry>,\n    fs: Arc<dyn Fs>,\n    cx: &mut App\n);\n```\n\nHere's a complete example of creating a local project:\n\n```rust\nuse gpui::App;\nuse client::Client;\nuse node_runtime::NodeRuntime;\nuse language::LanguageRegistry;\nuse std::sync::Arc;\n\nfn create_local_project(cx: &mut App) -> Entity<Project> {\n    // Initialize required dependencies\n    let client = Arc::new(Client::new(/* params */));\n    let node_runtime = NodeRuntime::new(/* params */);\n    let user_store = cx.new(|cx| UserStore::new(client.clone(), cx));\n    let languages = Arc::new(LanguageRegistry::new());\n    let fs = Arc::new(RealFs::new()); // or any other Fs implementation\n    \n    // Optional environment variables\n    let env = None; // or Some(HashMap::new())\n\n    // Create the project\n    Project::local(\n        client,\n        node_runtime,\n        user_store,\n        languages,\n        fs,\n        env,\n        cx,\n    )\n}\n```\n\nImportant notes:\n\n1. Before creating a project, you need to initialize settings:\n```rust\nProject::init_settings(cx);\n```\n\n2. The project should be initialized with:\n```rust\nProject::init(client, cx);\n```\n\n3. For testing, you can use the simpler `example()` or `test()` methods which provide more streamlined initialization.\n\n4. The project creation is usually part of a larger application setup where components like `Client`, `LanguageRegistry`, etc. are configured according to your specific needs.\n\n5. Each project type (local, remote, SSH) has different capabilities and requirements, so choose the appropriate constructor based on your use case.\n\n6. The created project is returned as an `Entity<Project>`, which is a reference-counted handle to the project that can be shared across the application.\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":47}}},{"id":{"replica_id":0,"value":37},"start":159577,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":48}}},{"id":{"replica_id":0,"value":38},"start":162475,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":49}}}],"summary":"To instantiate a Project, you have several options depending on your needs:","slash_command_output_sections":[{"range":{"start":0,"end":1},"icon":"Library","label":"Default","metadata":null},{"range":{"start":3,"end":2037},"icon":"Library","label":"Engineering","metadata":null},{"range":{"start":2038,"end":159542},"icon":"File","label":"zed/crates/project/src/project.rs","metadata":{"path":"zed/crates/project/src/project.rs"}}]}